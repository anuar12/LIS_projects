{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ggplot import *\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sklearn.linear_model as sklin\n",
    "import sklearn.metrics as skmet\n",
    "import sklearn.cross_validation as skcv\n",
    "import sklearn.grid_search as skgs\n",
    "import sklearn.preprocessing as skpr\n",
    "from sklearn.linear_model import Ridge\n",
    "import pandas as pd\n",
    "#from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model.stochastic_gradient import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.loadtxt(open(\"/Users/Anuar_The_Great/Desktop/Project/train.csv\", \"rb\"), \n",
    "                    delimiter=\",\", skiprows=1)\n",
    "test0 = np.loadtxt(open(\"/Users/Anuar_The_Great/Desktop/Project/test.csv\", \"rb\"), \n",
    "                    delimiter=\",\", skiprows=1)\n",
    "\n",
    "# Getting rid of the outlier\n",
    "train[207,:]\n",
    "train = np.delete(train, 207, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899, 15)\n",
      "test.shape (2000, 15)\n",
      "X.shape (899, 816)\n",
      "Y.shape (899,)\n",
      "test.shape (2000, 816)\n"
     ]
    }
   ],
   "source": [
    "def get_features(data):\n",
    "    return np.hstack((data, data*data))    # You can also do log and interaction terms!\n",
    "\n",
    "\n",
    "X = train[:, 2:17]\n",
    "print(X.shape)\n",
    "test = test0[:, 1:16]\n",
    "print('test.shape', test.shape)\n",
    "#X = more_terms(X)\n",
    "#X = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "#test = np.hstack((test, np.ones((test.shape[0], 1))))\n",
    "\n",
    "Y = train[:, 1]\n",
    "\n",
    "#print(len(feature_names))\n",
    "#X = skpr.scale(X)\n",
    "#test = skpr.scale(test)\n",
    "\n",
    "poly = skpr.PolynomialFeatures(degree=3, interaction_only=False)\n",
    "X = poly.fit_transform(X) \n",
    "poly = skpr.PolynomialFeatures(degree=3, interaction_only=False)\n",
    "test = poly.fit_transform(test)\n",
    "\n",
    "print('X.shape', X.shape)\n",
    "print('Y.shape', Y.shape)\n",
    "print('test.shape', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  12.,    7.,   18.,   59.,   92.,  116.,  139.,  114.,  115.,\n",
       "          92.,   59.,   38.,   26.,    4.,    8.]),\n",
       " array([-1.84155112, -1.45539467, -1.06923821, -0.68308176, -0.29692531,\n",
       "         0.08923115,  0.4753876 ,  0.86154406,  1.24770051,  1.63385696,\n",
       "         2.02001342,  2.40616987,  2.79232632,  3.17848278,  3.56463923,\n",
       "         3.95079569]),\n",
       " <a list of 15 Patch objects>)"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXZJaxFCXpBb5/21WNcVy3PDgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1126677d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.hist(Y, bins=20)\n",
    "plt.hist(test[:,6], bins=15)\n",
    "plt.hist(X[:,6], bins=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(gtruth, pred):\n",
    "    diff = gtruth - pred\n",
    "    return -np.sqrt(np.mean(np.square(diff)))\n",
    "scorefun = skmet.make_scorer(score)\n",
    "neg_scorefun = skmet.make_scorer(lambda x, y: -score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.6073967708\n",
      "-13.0829960186\n"
     ]
    }
   ],
   "source": [
    "# Solving Normal Equation\n",
    "beta = np.linalg.solve(X.T.dot(X) + 20*np.eye(X.shape[1]), X.T.dot(Y))\n",
    "\n",
    "# Training Error\n",
    "score(Y, beta.dot(X.T))\n",
    "\n",
    "X_train, X_test, y_train, y_test = skcv.train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=0)\n",
    "beta = np.linalg.solve(X_train.T.dot(X_train) + 125*np.eye(X_train.shape[1]), X_train.T.dot(y_train))\n",
    "print(score(y_test, X_test.dot(beta)))\n",
    "X_train, X_test, y_train, y_test = skcv.train_test_split(\n",
    "    X, Y, test_size=0.3, random_state=3)\n",
    "print(score(y_test, X_test.dot(beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#regressor_ridge = Ridge()\n",
    "\n",
    "param_grid = {'alpha': [1, 5, 10, 30, 50, 75, 100, 150, 200, 300, 750, 1000, 3000]}\n",
    "param_grid = {'alpha': np.linspace(10,500, 12),\n",
    "             'l1_ratio': [ 0.3, 0.5, 0.7],\n",
    "             'power_t': [0.1, 0.3, 0.6, 1],\n",
    "             'epsilon': [ 0.1, 1, 10]}\n",
    "\n",
    "#param_grid = {'alpha': [5000, 7500, 10000, 50000, 100000, 500000, 1000000]}\n",
    "\n",
    "sgd = SGDRegressor(average=False, eta0=0.01,\n",
    "       fit_intercept=True, learning_rate='invscaling',\n",
    "       loss='squared_loss', n_iter=5, penalty='elasticnet',\n",
    "       random_state=None, shuffle=True, verbose=1, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1442517257996.62, NNZs: 816, Bias: -83568634589.967987, T: 719, Avg. loss: 166511760709611993882951680.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1242470222765.08, NNZs: 816, Bias: -77236906703.436859, T: 1438, Avg. loss: 147284467568947150341537792.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1368862086234.15, NNZs: 816, Bias: -109550051974.164474, T: 2157, Avg. loss: 136114247635864560187998208.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1025791597953.20, NNZs: 816, Bias: -167814139853.739502, T: 2876, Avg. loss: 130034150129276130160541696.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1067171244650.89, NNZs: 816, Bias: -171429080903.732605, T: 3595, Avg. loss: 125700490640884682998153216.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1285602009568.21, NNZs: 816, Bias: 22930893263.156754, T: 719, Avg. loss: 155430881901944921099599872.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1248404302021.80, NNZs: 816, Bias: 85191549058.402908, T: 1438, Avg. loss: 145278259295860530291408896.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 987409406226.68, NNZs: 816, Bias: 62053067159.618744, T: 2157, Avg. loss: 139697387018604425668198400.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 953022079452.29, NNZs: 816, Bias: 60009031533.968819, T: 2876, Avg. loss: 133953630707612593753686016.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 939754210417.54, NNZs: 816, Bias: 69973230592.035965, T: 3595, Avg. loss: 128703935720162304030932992.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1145293387005.50, NNZs: 816, Bias: -43412719833.668953, T: 719, Avg. loss: 165156258051644116432846848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1229842621198.51, NNZs: 816, Bias: -104288194285.254013, T: 1438, Avg. loss: 152078180530458065744429056.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1036602042395.06, NNZs: 816, Bias: -34077660901.043274, T: 2157, Avg. loss: 144953749397635661182271488.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1195961447005.52, NNZs: 816, Bias: -7183235326.109332, T: 2876, Avg. loss: 135560405639269758277779456.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1159661677118.98, NNZs: 816, Bias: 363219551.553239, T: 3595, Avg. loss: 128923346823368791088431104.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1128416076564.06, NNZs: 816, Bias: -43916451845.011841, T: 719, Avg. loss: 174965829313059441732485120.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 995721985372.93, NNZs: 816, Bias: 56544567946.982254, T: 1438, Avg. loss: 144612025090642526888525824.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1417613513833.80, NNZs: 816, Bias: 69574751863.047150, T: 2157, Avg. loss: 135345328285213507828318208.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1072638288905.04, NNZs: 816, Bias: -16359352413.060833, T: 2876, Avg. loss: 129584818548627032669945856.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 967091009908.94, NNZs: 816, Bias: -11026441647.424419, T: 3595, Avg. loss: 123723385441503143872430080.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1248328438564.33, NNZs: 816, Bias: 33607006351.298481, T: 720, Avg. loss: 158416560920926847665963008.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1418588902718.38, NNZs: 816, Bias: -81018878870.835846, T: 1440, Avg. loss: 143554481052596348953559040.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1165254303521.15, NNZs: 816, Bias: -35191531096.137245, T: 2160, Avg. loss: 136037816274115239872561152.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1192979861880.92, NNZs: 816, Bias: -20552149776.210720, T: 2880, Avg. loss: 129244955640652939386683392.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1223682532229.98, NNZs: 816, Bias: 46748332882.294197, T: 3600, Avg. loss: 124647500781475095268818944.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 476562109636.50, NNZs: 816, Bias: -1960869647.334928, T: 719, Avg. loss: 24652207954529666153316352.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 426055813727.98, NNZs: 816, Bias: 1297325980.786616, T: 1438, Avg. loss: 18291760332938503971143680.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 392742200315.43, NNZs: 816, Bias: -4739855221.592328, T: 2157, Avg. loss: 15057587762947290306707456.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 369167896331.24, NNZs: 816, Bias: -3453463169.788382, T: 2876, Avg. loss: 12976861854972556831883264.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 363248174802.80, NNZs: 816, Bias: -7115004351.975580, T: 3595, Avg. loss: 11593190264276298391093248.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 520664636698.11, NNZs: 816, Bias: -20656711986.340645, T: 719, Avg. loss: 27481586882103959072276480.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 442272920156.49, NNZs: 816, Bias: 2078977515.939657, T: 1438, Avg. loss: 19617079133796588563988480.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 389540444440.72, NNZs: 816, Bias: -3093904546.407891, T: 2157, Avg. loss: 15840977039236406360145920.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 338497165445.58, NNZs: 816, Bias: 8953204776.807854, T: 2876, Avg. loss: 13693105788475724819070976.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 359043374680.95, NNZs: 816, Bias: 10611079691.594023, T: 3595, Avg. loss: 12188639814645321868247040.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 542027044688.65, NNZs: 816, Bias: 1620570055.218793, T: 719, Avg. loss: 25055159618093384204288000.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 451433981881.10, NNZs: 816, Bias: 10216580079.221634, T: 1438, Avg. loss: 18758172774637572206886912.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 429438164170.68, NNZs: 816, Bias: 14002047686.394403, T: 2157, Avg. loss: 15255397729833565110140928.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 368920935291.01, NNZs: 816, Bias: 15557547043.201624, T: 2876, Avg. loss: 13092904568004830226808832.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 382969068296.93, NNZs: 816, Bias: 19210648868.459896, T: 3595, Avg. loss: 11723131153791627774918656.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 540751381707.03, NNZs: 816, Bias: -14234115374.557568, T: 719, Avg. loss: 25881425523726650951335936.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 418708798775.19, NNZs: 816, Bias: -21132405046.395256, T: 1438, Avg. loss: 18741153813310362720665600.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 472252174608.14, NNZs: 816, Bias: -259108060.190624, T: 2157, Avg. loss: 15339595630285491663798272.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 410675129610.45, NNZs: 816, Bias: -21873994960.637829, T: 2876, Avg. loss: 13031793253821124744052736.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 349582477780.77, NNZs: 816, Bias: -22328140889.658867, T: 3595, Avg. loss: 11530996703086824636022784.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 470027700191.67, NNZs: 816, Bias: -1293164008.371547, T: 720, Avg. loss: 25441522289090758822592512.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 399075649175.57, NNZs: 816, Bias: 30063802384.513592, T: 1440, Avg. loss: 19047682383814429822156800.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 387404137685.42, NNZs: 816, Bias: 17214337540.176559, T: 2160, Avg. loss: 15396852165330450031575040.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 361493977743.72, NNZs: 816, Bias: 25429738400.047134, T: 2880, Avg. loss: 13365447289155641514393600.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 439396229381.88, NNZs: 816, Bias: 35696030212.907356, T: 3600, Avg. loss: 11794906820136396971311104.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 114698457217.92, NNZs: 816, Bias: 3166026432.396119, T: 719, Avg. loss: 1351638920495591931772928.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 57003655059.44, NNZs: 816, Bias: 2836890457.535198, T: 1438, Avg. loss: 731296736196869067112448.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27559110590.69, NNZs: 816, Bias: 2466720699.277076, T: 2157, Avg. loss: 497207556137322559832064.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13314355393.38, NNZs: 816, Bias: 2515709210.073290, T: 2876, Avg. loss: 374135750733094394527744.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7531596906.34, NNZs: 816, Bias: 2516335648.575036, T: 3595, Avg. loss: 299391446763818251714560.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 119731426778.91, NNZs: 816, Bias: -3370893481.756814, T: 719, Avg. loss: 1673661807509379253010432.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 56137358317.82, NNZs: 816, Bias: -3641157480.578479, T: 1438, Avg. loss: 899572269906800540647424.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 27331060331.19, NNZs: 816, Bias: -3804491946.764670, T: 2157, Avg. loss: 606340003553059887120384.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13612229221.39, NNZs: 816, Bias: -3527439176.905001, T: 2876, Avg. loss: 455639995306683205156864.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7628232687.35, NNZs: 816, Bias: -3516667830.823481, T: 3595, Avg. loss: 364613924497565008527360.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 118158327983.22, NNZs: 816, Bias: -2873259662.655545, T: 719, Avg. loss: 1480161810121148696887296.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54667871394.03, NNZs: 816, Bias: -2927637274.905446, T: 1438, Avg. loss: 810907664144950173368320.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30597031484.14, NNZs: 816, Bias: -3534305534.402716, T: 2157, Avg. loss: 549591644598591532564480.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14736657333.92, NNZs: 816, Bias: -3233739946.707721, T: 2876, Avg. loss: 413540944328493811892224.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8302974349.90, NNZs: 816, Bias: -3211980450.567364, T: 3595, Avg. loss: 331003747866126355267584.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 104632969759.14, NNZs: 816, Bias: 7533589.851604, T: 719, Avg. loss: 1040307524388617277407232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 53756680750.33, NNZs: 816, Bias: -1104114271.107607, T: 1438, Avg. loss: 561307659009996124848128.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 26590819071.17, NNZs: 816, Bias: -1319005275.570008, T: 2157, Avg. loss: 380894598315362261925888.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13697502438.17, NNZs: 816, Bias: -1251015505.113451, T: 2876, Avg. loss: 287288464512745214050304.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7591370295.50, NNZs: 816, Bias: -1200978773.143590, T: 3595, Avg. loss: 229947335194717177511936.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 114257620767.10, NNZs: 816, Bias: -7770120672.192780, T: 720, Avg. loss: 1044842149533606553321472.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 53128540205.37, NNZs: 816, Bias: -6600813007.148469, T: 1440, Avg. loss: 592053485689385305243648.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24778564745.05, NNZs: 816, Bias: -6362894290.806483, T: 2160, Avg. loss: 400094232567920092774400.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 11933929744.85, NNZs: 816, Bias: -6256201296.685494, T: 2880, Avg. loss: 300859972609424490496000.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6923206109.82, NNZs: 816, Bias: -6140626199.101017, T: 3600, Avg. loss: 240761258579374339260416.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 414218.20, NNZs: 815, Bias: 363.191992, T: 719, Avg. loss: 3208814435024.422852\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 357645.50, NNZs: 816, Bias: 733.440055, T: 1438, Avg. loss: 2169886714284.178711\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 330925.42, NNZs: 816, Bias: 626.487343, T: 2157, Avg. loss: 1700054198797.832764\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 313529.94, NNZs: 816, Bias: 715.208390, T: 2876, Avg. loss: 1430477537002.146484\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 301060.38, NNZs: 816, Bias: 686.143219, T: 3595, Avg. loss: 1251063890263.962402\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 72530.94, NNZs: 816, Bias: -994.834109, T: 719, Avg. loss: 184266444981.444916\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 60278.77, NNZs: 816, Bias: -950.398302, T: 1438, Avg. loss: 116599230123.033539\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 54799.95, NNZs: 816, Bias: -910.987132, T: 2157, Avg. loss: 87446783662.578033\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 51456.93, NNZs: 815, Bias: -908.736117, T: 2876, Avg. loss: 71039755213.948349\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49120.75, NNZs: 816, Bias: -888.312281, T: 3595, Avg. loss: 60434837874.089828\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 30329.56, NNZs: 816, Bias: -186.870729, T: 719, Avg. loss: 13932348189.154762\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 26388.11, NNZs: 815, Bias: -202.278672, T: 1438, Avg. loss: 9784722724.207262\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 24466.31, NNZs: 816, Bias: -194.473320, T: 2157, Avg. loss: 7808995476.035439\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23278.54, NNZs: 816, Bias: -191.190355, T: 2876, Avg. loss: 6618141973.484374\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22416.49, NNZs: 816, Bias: -190.129293, T: 3595, Avg. loss: 5819264705.840193\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24366.57, NNZs: 816, Bias: 114.379620, T: 719, Avg. loss: 19552301709.223873\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20932.96, NNZs: 815, Bias: 95.178687, T: 1438, Avg. loss: 11992477644.649374\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19235.19, NNZs: 816, Bias: 90.108123, T: 2157, Avg. loss: 8995358521.410740\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18157.04, NNZs: 815, Bias: 90.300892, T: 2876, Avg. loss: 7344130861.515022\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17381.52, NNZs: 816, Bias: 84.093588, T: 3595, Avg. loss: 6283146092.434040\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 11607343.29, NNZs: 816, Bias: -155102.539628, T: 720, Avg. loss: 4116118252009775.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 9717985.65, NNZs: 816, Bias: -154975.850598, T: 1440, Avg. loss: 2620409426351792.500000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 8884620.56, NNZs: 816, Bias: -152704.344456, T: 2160, Avg. loss: 1978968362656916.250000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8367127.70, NNZs: 816, Bias: -154183.766668, T: 2880, Avg. loss: 1619070391536097.750000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7996396.98, NNZs: 816, Bias: -151576.743129, T: 3600, Avg. loss: 1385094272133353.750000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1240995497104.23, NNZs: 816, Bias: 11701079614.900616, T: 719, Avg. loss: 190299352332309356330614784.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1249642152348.77, NNZs: 816, Bias: -10382183559.188780, T: 1438, Avg. loss: 172555296500100686109736960.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1324288400580.25, NNZs: 816, Bias: 48845469568.820160, T: 2157, Avg. loss: 160794712376759261400662016.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1153064364859.48, NNZs: 816, Bias: 31349169319.782555, T: 2876, Avg. loss: 151908059712079570936004608.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1144036188984.24, NNZs: 816, Bias: -16395112018.121004, T: 3595, Avg. loss: 145907452423364755425591296.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1444200913393.71, NNZs: 816, Bias: 47026248253.964020, T: 719, Avg. loss: 169757517338165196468781056.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1478604937044.95, NNZs: 816, Bias: 104576420281.305344, T: 1438, Avg. loss: 156959729775284500410925056.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1434894974045.40, NNZs: 816, Bias: 126278957234.915466, T: 2157, Avg. loss: 145537960223301826972221440.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1457706655136.83, NNZs: 816, Bias: 160005586372.185791, T: 2876, Avg. loss: 138979162011607273316548608.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1359246447662.75, NNZs: 816, Bias: 206847586747.409515, T: 3595, Avg. loss: 135970369700687245113032704.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1235582337767.13, NNZs: 816, Bias: -13457471800.363243, T: 719, Avg. loss: 173274635709795854704443392.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1367017209480.63, NNZs: 816, Bias: 30658482050.812023, T: 1438, Avg. loss: 158965046305512664684560384.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1184022130469.75, NNZs: 816, Bias: -34686473414.313637, T: 2157, Avg. loss: 148727595988968642768273408.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1355006347964.72, NNZs: 816, Bias: -62993852107.580925, T: 2876, Avg. loss: 142880880503963336505819136.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1296636886674.51, NNZs: 816, Bias: -45584142459.829437, T: 3595, Avg. loss: 139647234127907823726624768.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1507488728199.03, NNZs: 816, Bias: 98092109695.745697, T: 719, Avg. loss: 171029902968255208633663488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1322122572771.91, NNZs: 816, Bias: -21589476648.744343, T: 1438, Avg. loss: 153087131920863105036320768.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1363020723370.59, NNZs: 816, Bias: -69584059643.002914, T: 2157, Avg. loss: 148041268507557567060246528.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1129010222313.79, NNZs: 816, Bias: -125387882796.112228, T: 2876, Avg. loss: 145572423752660912858726400.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1088993201038.27, NNZs: 816, Bias: -79598789137.934036, T: 3595, Avg. loss: 140691241530343349651767296.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1347429345267.61, NNZs: 816, Bias: 29530030406.559483, T: 720, Avg. loss: 190176728723919097550602240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1692587618436.67, NNZs: 816, Bias: -21699959468.526951, T: 1440, Avg. loss: 172771002877275086436433920.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1307400637446.42, NNZs: 816, Bias: -6699708097.546611, T: 2160, Avg. loss: 163046578290096747956928512.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1276193232922.39, NNZs: 816, Bias: 3155871197.858320, T: 2880, Avg. loss: 156875283237121673735962624.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1106273920601.66, NNZs: 816, Bias: 2163336042.681568, T: 3600, Avg. loss: 151002578578260181934669824.000000\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 601006771914.68, NNZs: 816, Bias: -9661308305.917683, T: 719, Avg. loss: 29219869831596206846902272.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 502588624612.94, NNZs: 816, Bias: 2366228451.801325, T: 1438, Avg. loss: 20517787389389136264691712.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 449648720245.13, NNZs: 816, Bias: 3872835492.083066, T: 2157, Avg. loss: 16854061211684446320721920.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 455673191661.24, NNZs: 816, Bias: 763545919.612069, T: 2876, Avg. loss: 14490251720773759940952064.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 405293408286.01, NNZs: 816, Bias: -10073102866.166372, T: 3595, Avg. loss: 13002932267594259504300032.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 546322037619.54, NNZs: 816, Bias: -6490378470.558802, T: 719, Avg. loss: 29405221761576853777154048.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 506715623020.48, NNZs: 816, Bias: -18529516965.497070, T: 1438, Avg. loss: 21070026530887648543768576.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 491716337177.32, NNZs: 816, Bias: -40408493870.426033, T: 2157, Avg. loss: 17215036033060106171056128.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 408260848687.26, NNZs: 816, Bias: -57584487847.377792, T: 2876, Avg. loss: 14877651541373029269372928.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 439195865312.09, NNZs: 816, Bias: -51397601912.458755, T: 3595, Avg. loss: 13184677108464776141340672.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 578849677652.00, NNZs: 816, Bias: 6894125618.362622, T: 719, Avg. loss: 29389219921101204347682816.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 500880096125.34, NNZs: 816, Bias: -966151634.882637, T: 1438, Avg. loss: 21230425903274700371394560.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 423642477583.04, NNZs: 816, Bias: -16788911024.145445, T: 2157, Avg. loss: 17472015196436610825584640.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 388134654916.12, NNZs: 816, Bias: -20298231113.191521, T: 2876, Avg. loss: 15108731205278420046970880.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 436000497747.45, NNZs: 816, Bias: -25441823841.790798, T: 3595, Avg. loss: 13435912458585122348728320.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 551062457321.43, NNZs: 816, Bias: 3681786807.354623, T: 719, Avg. loss: 29576959622527445356249088.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 518759313579.29, NNZs: 816, Bias: -820623379.092336, T: 1438, Avg. loss: 20553898179518441757605888.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 401728412057.83, NNZs: 816, Bias: 21389385435.727589, T: 2157, Avg. loss: 16893310572452189143302144.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 401662526708.22, NNZs: 816, Bias: 19312877171.424126, T: 2876, Avg. loss: 14439712891929325169803264.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 408579394075.95, NNZs: 816, Bias: 15658188420.332289, T: 3595, Avg. loss: 12870031831442223704047616.000000\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 494486259155.26, NNZs: 816, Bias: 14857397189.226118, T: 720, Avg. loss: 28278922881529280446070784.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 560784410008.55, NNZs: 816, Bias: 19104308028.930538, T: 1440, Avg. loss: 20724908602975003177123840.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 444700449976.93, NNZs: 816, Bias: 15960834268.377796, T: 2160, Avg. loss: 17099027862810304555515904.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 442233585493.61, NNZs: 816, Bias: 13126440863.600458, T: 2880, Avg. loss: 14832384804805663195660288.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 370805320351.85, NNZs: 816, Bias: 12451247352.868683, T: 3600, Avg. loss: 13224909341169593972948992.000000\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 135744608895.85, NNZs: 816, Bias: 1451326208.611567, T: 719, Avg. loss: 1035010425052697230049280.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 69410492410.42, NNZs: 816, Bias: 1561448776.213068, T: 1438, Avg. loss: 592397212160852355973120.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 41201496251.37, NNZs: 816, Bias: 1296600432.821368, T: 2157, Avg. loss: 403753676630192377823232.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23418818730.45, NNZs: 816, Bias: 1041569408.264530, T: 2876, Avg. loss: 305353682787988349648896.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15304895506.85, NNZs: 816, Bias: 1078512092.990033, T: 3595, Avg. loss: 244558494291024710467584.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 142249862886.81, NNZs: 816, Bias: -4761036408.204965, T: 719, Avg. loss: 1310920200625413521670144.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 74755928945.97, NNZs: 816, Bias: -3912217734.534921, T: 1438, Avg. loss: 735603728185025137475584.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 44756029213.32, NNZs: 816, Bias: -3705258738.312704, T: 2157, Avg. loss: 506557098417537782120448.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26174955474.70, NNZs: 816, Bias: -3583000756.452400, T: 2876, Avg. loss: 383552050918808935727104.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16446505479.78, NNZs: 816, Bias: -3565773140.250550, T: 3595, Avg. loss: 307281811564027462025216.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 130965082985.49, NNZs: 816, Bias: 2696960037.987665, T: 719, Avg. loss: 1327954950082683176222720.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 69386559764.35, NNZs: 816, Bias: 3668255944.736560, T: 1438, Avg. loss: 737479952627577116426240.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40058430591.57, NNZs: 816, Bias: 2645002871.805489, T: 2157, Avg. loss: 508716720936064441647104.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23746586358.23, NNZs: 816, Bias: 2530239268.838677, T: 2876, Avg. loss: 383480287494249813901312.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15360653394.39, NNZs: 816, Bias: 2389377779.126259, T: 3595, Avg. loss: 307097381064617746235392.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 137143822904.61, NNZs: 816, Bias: 2240464912.350427, T: 719, Avg. loss: 899794960374476715327488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 67920219246.78, NNZs: 816, Bias: 804985694.053931, T: 1438, Avg. loss: 515914695818608119906304.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38830581079.07, NNZs: 816, Bias: 1235128720.091465, T: 2157, Avg. loss: 355231640096902794444800.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 22462124202.80, NNZs: 816, Bias: 1135133012.348047, T: 2876, Avg. loss: 268147972720790075342848.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15097349444.96, NNZs: 816, Bias: 1086966997.892813, T: 3595, Avg. loss: 214732020017506837069824.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 138059777305.41, NNZs: 816, Bias: 187236816.664308, T: 720, Avg. loss: 1395849522146572985434112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 64504710783.40, NNZs: 816, Bias: 218699987.923647, T: 1440, Avg. loss: 782275997427398801883136.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35472195329.07, NNZs: 816, Bias: 254467693.423382, T: 2160, Avg. loss: 528698253426736662315008.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21469784468.57, NNZs: 816, Bias: -57675961.728389, T: 2880, Avg. loss: 398176962728421765414912.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14046323156.09, NNZs: 816, Bias: 41579621.862509, T: 3600, Avg. loss: 318738630980391556612096.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 48645430.52, NNZs: 816, Bias: 418871.011481, T: 719, Avg. loss: 57285788754463256.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 41051947.15, NNZs: 816, Bias: 336496.804123, T: 1438, Avg. loss: 39268602401232880.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37677561.85, NNZs: 816, Bias: 298825.356452, T: 2157, Avg. loss: 30571133627711500.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 35566514.25, NNZs: 816, Bias: 274829.335192, T: 2876, Avg. loss: 25477399390854624.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 34111780.34, NNZs: 816, Bias: 265994.905386, T: 3595, Avg. loss: 22077584174836928.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1423350.94, NNZs: 816, Bias: 8595.396644, T: 719, Avg. loss: 42680777751958.406250\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1239268.58, NNZs: 816, Bias: 8719.621499, T: 1438, Avg. loss: 28706519432974.859375\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1152050.86, NNZs: 816, Bias: 8173.567606, T: 2157, Avg. loss: 22405076038764.363281\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1098225.64, NNZs: 816, Bias: 8184.365457, T: 2876, Avg. loss: 18719680098039.562500\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1059905.46, NNZs: 816, Bias: 7871.993613, T: 3595, Avg. loss: 16288117373832.947266\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1950742.75, NNZs: 816, Bias: 2776.407753, T: 719, Avg. loss: 90657335039941.171875\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1684829.18, NNZs: 816, Bias: 3995.011049, T: 1438, Avg. loss: 59386502093374.273438\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1561075.74, NNZs: 816, Bias: 3675.868233, T: 2157, Avg. loss: 45880847790943.851562\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1484912.90, NNZs: 816, Bias: 3746.466170, T: 2876, Avg. loss: 38175186792599.375000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1430205.95, NNZs: 816, Bias: 3821.207231, T: 3595, Avg. loss: 33135538124332.136719\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 4531.51, NNZs: 815, Bias: -36.479586, T: 719, Avg. loss: 394087909.455997\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4024.64, NNZs: 813, Bias: -33.343696, T: 1438, Avg. loss: 257913701.422399\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3769.83, NNZs: 816, Bias: -32.344970, T: 2157, Avg. loss: 201417878.855163\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3605.80, NNZs: 811, Bias: -31.775305, T: 2876, Avg. loss: 169210578.472284\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3489.03, NNZs: 813, Bias: -31.382958, T: 3595, Avg. loss: 147968044.280415\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 408296.83, NNZs: 816, Bias: 5433.938735, T: 720, Avg. loss: 4326297964970.312012\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 351207.25, NNZs: 816, Bias: 5133.933998, T: 1440, Avg. loss: 2813727386918.140137\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 325053.77, NNZs: 816, Bias: 4879.190242, T: 2160, Avg. loss: 2155700812406.761963\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 309085.63, NNZs: 816, Bias: 4711.724560, T: 2880, Avg. loss: 1780921534878.662842\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 297769.49, NNZs: 816, Bias: 4649.262217, T: 3600, Avg. loss: 1535719604619.601318\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1619162431430.37, NNZs: 816, Bias: 27668283113.485443, T: 719, Avg. loss: 246210080585373438042963968.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1691572272584.76, NNZs: 816, Bias: 70251211178.532318, T: 1438, Avg. loss: 213006954361561960713027584.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1682336973395.65, NNZs: 816, Bias: 40707319380.907608, T: 2157, Avg. loss: 197001699335500662434693120.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1475447454326.81, NNZs: 816, Bias: 4375827102.901195, T: 2876, Avg. loss: 184684830701900171638210560.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1658535168079.63, NNZs: 816, Bias: 113459629321.723679, T: 3595, Avg. loss: 176623472942525057970733056.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1499435845629.21, NNZs: 816, Bias: 24546804971.598305, T: 719, Avg. loss: 228968135326891530864558080.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1607639427451.77, NNZs: 816, Bias: 19776064584.426865, T: 1438, Avg. loss: 198838117608582998359277568.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1221407918345.41, NNZs: 816, Bias: 36465029897.783165, T: 2157, Avg. loss: 190723057427353774975877120.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1463203277286.41, NNZs: 816, Bias: 49404885959.427048, T: 2876, Avg. loss: 180157905432073703591510016.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1706531970772.87, NNZs: 816, Bias: 100579428750.410751, T: 3595, Avg. loss: 173059916476938719078645760.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1682183976174.62, NNZs: 816, Bias: 50299103972.915100, T: 719, Avg. loss: 197271691514565770776412160.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1678271418187.58, NNZs: 816, Bias: -10036642828.722309, T: 1438, Avg. loss: 195920121105761285542248448.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1456256722858.61, NNZs: 816, Bias: -67933436935.122635, T: 2157, Avg. loss: 186842256399888339198541824.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1430374935982.21, NNZs: 816, Bias: -12765898906.638762, T: 2876, Avg. loss: 177606328213976233701015552.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1695429424809.22, NNZs: 816, Bias: 24418152866.588295, T: 3595, Avg. loss: 170680643614702377891790848.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1879266166555.81, NNZs: 816, Bias: -52536139888.995438, T: 719, Avg. loss: 223404400033967968098451456.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1649302937517.77, NNZs: 816, Bias: 22073485211.133465, T: 1438, Avg. loss: 202832165443739874270117888.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1464823839269.13, NNZs: 816, Bias: -11791480153.305328, T: 2157, Avg. loss: 185705823472757622028894208.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1617333929518.23, NNZs: 816, Bias: -59635860767.501190, T: 2876, Avg. loss: 175523409369239037197418496.000000\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1497773567237.73, NNZs: 816, Bias: -39715149848.370941, T: 3595, Avg. loss: 167905196341788033358495744.000000\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1953858746127.70, NNZs: 816, Bias: 69396064952.335083, T: 720, Avg. loss: 223767547273343246761197568.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1785910482141.22, NNZs: 816, Bias: 51233178412.589783, T: 1440, Avg. loss: 200208962441336796139749376.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1662524223022.63, NNZs: 816, Bias: 53865792894.749748, T: 2160, Avg. loss: 189783418793286390490595328.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1458118378223.50, NNZs: 816, Bias: 11916583850.528254, T: 2880, Avg. loss: 181809503268587818855694336.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1644934452391.54, NNZs: 816, Bias: -57882494558.732399, T: 3600, Avg. loss: 174979028163624286294114304.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 672215432397.97, NNZs: 816, Bias: 15003440075.561983, T: 719, Avg. loss: 32675694018636606513086464.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 628247905439.10, NNZs: 816, Bias: 16894651732.556570, T: 1438, Avg. loss: 24212243972867115341316096.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 551124029011.45, NNZs: 816, Bias: 20277605291.470039, T: 2157, Avg. loss: 19947321574983389295935488.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 530853084885.59, NNZs: 816, Bias: 7017440396.636971, T: 2876, Avg. loss: 17226290599448760094294016.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 488598170962.97, NNZs: 816, Bias: 13409123461.928665, T: 3595, Avg. loss: 15388306268236904241561600.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 734904913428.48, NNZs: 816, Bias: -20281098443.136990, T: 719, Avg. loss: 32481264022402506302685184.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 549747821236.07, NNZs: 816, Bias: -19860952852.060280, T: 1438, Avg. loss: 23474275806175993723355136.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 544744591871.28, NNZs: 816, Bias: -9751394792.998524, T: 2157, Avg. loss: 19310476575244981167456256.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 478016167618.50, NNZs: 816, Bias: -7655849291.862510, T: 2876, Avg. loss: 16666272510296334054457344.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 445545517912.57, NNZs: 816, Bias: -19022506856.457481, T: 3595, Avg. loss: 14870874260956625737089024.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 682286589284.96, NNZs: 816, Bias: 17183033666.810722, T: 719, Avg. loss: 34397130882552683558862848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 689186069546.16, NNZs: 816, Bias: 31295754981.101025, T: 1438, Avg. loss: 24252388609017721349210112.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 577057577848.59, NNZs: 816, Bias: 47067549561.217972, T: 2157, Avg. loss: 19834064880095814351847424.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 534182636939.63, NNZs: 816, Bias: 46826069300.596779, T: 2876, Avg. loss: 17083064761040226496806912.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 501167500124.99, NNZs: 816, Bias: 40126512694.572205, T: 3595, Avg. loss: 15236048636113978057031680.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 672138298230.14, NNZs: 816, Bias: -15157801706.189926, T: 719, Avg. loss: 29422637262309059945562112.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 582174253003.21, NNZs: 816, Bias: 4598942090.972112, T: 1438, Avg. loss: 21732357397099403850809344.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 510080216018.94, NNZs: 816, Bias: -6298022855.000284, T: 2157, Avg. loss: 17862921286346283411308544.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 537864757683.22, NNZs: 816, Bias: -18907481008.170174, T: 2876, Avg. loss: 15513461393750678923378688.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 475677226273.44, NNZs: 816, Bias: -2872886172.724036, T: 3595, Avg. loss: 13960925892215699750780928.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 700701730762.03, NNZs: 816, Bias: 890012040.215668, T: 720, Avg. loss: 33041146935499656351711232.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 576704841777.73, NNZs: 816, Bias: -1216487650.967892, T: 1440, Avg. loss: 24000455163646231430823936.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 506938546585.71, NNZs: 816, Bias: 3507781432.717220, T: 2160, Avg. loss: 19504090891151532519063552.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 497187510397.57, NNZs: 816, Bias: 8547393747.697585, T: 2880, Avg. loss: 16903446437699505260331008.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 468861477674.12, NNZs: 816, Bias: -3936948697.372749, T: 3600, Avg. loss: 15060852628300190627921920.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 199461507277.10, NNZs: 816, Bias: -5274441390.365054, T: 719, Avg. loss: 2325370894029357462847488.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 102803992339.37, NNZs: 816, Bias: -4966988864.731898, T: 1438, Avg. loss: 1300558558989942832234496.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66715546423.93, NNZs: 816, Bias: -4530668370.842666, T: 2157, Avg. loss: 883963587316725883863040.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47674405613.50, NNZs: 816, Bias: -4025754533.464719, T: 2876, Avg. loss: 668514203146890806034432.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 36298215169.06, NNZs: 816, Bias: -4103441657.622513, T: 3595, Avg. loss: 535727066033934997389312.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 174572398756.39, NNZs: 816, Bias: -3280093561.648034, T: 719, Avg. loss: 1544634223214560802766848.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 99714141043.02, NNZs: 816, Bias: -1313710769.631409, T: 1438, Avg. loss: 883159305368115045466112.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63992750425.09, NNZs: 816, Bias: -1795479413.223362, T: 2157, Avg. loss: 604667108875233287733248.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44237023412.43, NNZs: 816, Bias: -1556769990.342723, T: 2876, Avg. loss: 457298072193923647799296.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33070558056.70, NNZs: 816, Bias: -1576155481.911945, T: 3595, Avg. loss: 366676922126646913269760.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 177101781354.56, NNZs: 816, Bias: -2184603969.594491, T: 719, Avg. loss: 1843151288471028439711744.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 96171880920.27, NNZs: 816, Bias: -983579328.994850, T: 1438, Avg. loss: 1034998330079716170530816.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 61316802309.29, NNZs: 816, Bias: -1090540423.072480, T: 2157, Avg. loss: 702737129309582959575040.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 43640264549.64, NNZs: 816, Bias: -644794323.980222, T: 2876, Avg. loss: 530964198540284113453056.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 32608188154.01, NNZs: 816, Bias: -549913789.690051, T: 3595, Avg. loss: 425909903910109645373440.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 185030411787.41, NNZs: 816, Bias: 478636224.790219, T: 719, Avg. loss: 1609985435714412097830912.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 100446259634.24, NNZs: 816, Bias: -267599873.227484, T: 1438, Avg. loss: 918038761299936949567488.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 63534761003.24, NNZs: 816, Bias: -74144470.108724, T: 2157, Avg. loss: 630500591595991752245248.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 44345095811.77, NNZs: 816, Bias: -11957445.248027, T: 2876, Avg. loss: 476180236721343334187008.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 33449645075.13, NNZs: 816, Bias: -94241479.396422, T: 3595, Avg. loss: 382127643228970546102272.000000\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 204951134402.40, NNZs: 816, Bias: 7177918555.077879, T: 720, Avg. loss: 2038306485693828086890496.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 110131962622.63, NNZs: 816, Bias: 6077829726.337761, T: 1440, Avg. loss: 1155090267838326478209024.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 69297972025.65, NNZs: 816, Bias: 5228381293.833393, T: 2160, Avg. loss: 789745819036625263394816.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47862217630.81, NNZs: 816, Bias: 4669321173.641244, T: 2880, Avg. loss: 596573897920285346103296.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 35594053334.48, NNZs: 816, Bias: 4586174513.911814, T: 3600, Avg. loss: 478517093826383117811712.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 11704596.06, NNZs: 816, Bias: 46260.515441, T: 719, Avg. loss: 3780954400308580.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 10197206.27, NNZs: 816, Bias: 49501.631781, T: 1438, Avg. loss: 2433150615826777.500000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9484438.26, NNZs: 816, Bias: 46994.276891, T: 2157, Avg. loss: 1869244748487533.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9039538.61, NNZs: 816, Bias: 50865.093519, T: 2876, Avg. loss: 1550899603866724.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8724688.39, NNZs: 816, Bias: 50147.939938, T: 3595, Avg. loss: 1344288534424849.250000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 327042.11, NNZs: 816, Bias: 7134.679283, T: 719, Avg. loss: 2426701660559.385742\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 287949.85, NNZs: 816, Bias: 6490.426617, T: 1438, Avg. loss: 1627827421087.559814\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 268976.12, NNZs: 816, Bias: 6345.711892, T: 2157, Avg. loss: 1276014166434.082275\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 256702.14, NNZs: 816, Bias: 6134.344701, T: 2876, Avg. loss: 1073576965444.810547\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 248289.44, NNZs: 815, Bias: 6033.438701, T: 3595, Avg. loss: 938115378879.962891\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 379.58, NNZs: 781, Bias: -1.823492, T: 719, Avg. loss: 2266093.696284\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 339.62, NNZs: 770, Bias: -1.990273, T: 1438, Avg. loss: 1603528.547321\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 320.66, NNZs: 760, Bias: -2.022721, T: 2157, Avg. loss: 1281609.865962\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 308.72, NNZs: 763, Bias: -1.991084, T: 2876, Avg. loss: 1088648.599562\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 300.52, NNZs: 764, Bias: -2.018768, T: 3595, Avg. loss: 957837.075027\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 3535.16, NNZs: 815, Bias: -24.220636, T: 719, Avg. loss: 241561557.822888\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3120.12, NNZs: 813, Bias: -24.546659, T: 1438, Avg. loss: 167227396.351078\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2922.08, NNZs: 814, Bias: -25.265932, T: 2157, Avg. loss: 132476230.268681\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2794.84, NNZs: 814, Bias: -24.508920, T: 2876, Avg. loss: 112120074.414263\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2708.50, NNZs: 811, Bias: -24.123625, T: 3595, Avg. loss: 98420355.060048\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 78119.18, NNZs: 816, Bias: -455.618066, T: 720, Avg. loss: 201944509708.051636\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 69930.10, NNZs: 816, Bias: -467.169843, T: 1440, Avg. loss: 120242699763.832840\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66231.40, NNZs: 813, Bias: -465.648879, T: 2160, Avg. loss: 88852031744.973953\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 63857.63, NNZs: 816, Bias: -447.653602, T: 2880, Avg. loss: 72020870075.323425\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 62116.18, NNZs: 816, Bias: -451.623805, T: 3600, Avg. loss: 61403440784.354736\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1114655779352.00, NNZs: 816, Bias: 39270002951.210487, T: 719, Avg. loss: 158398404534223985319084032.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1167528544521.10, NNZs: 816, Bias: -8911963666.973598, T: 1438, Avg. loss: 144180680343572199164084224.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1244808920580.84, NNZs: 816, Bias: 42064804333.563637, T: 2157, Avg. loss: 137358370797945805867057152.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1255976845978.01, NNZs: 816, Bias: 46313772780.448578, T: 2876, Avg. loss: 130228739669163402686627840.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 997858920636.29, NNZs: 816, Bias: 20742181471.152496, T: 3595, Avg. loss: 125974678037362960081354752.000000\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1122511792743.93, NNZs: 816, Bias: -38098788373.994873, T: 719, Avg. loss: 146170636540247222219964416.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1196640059031.74, NNZs: 816, Bias: -63578208968.088837, T: 1438, Avg. loss: 135719833469305132890980352.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1138763736147.39, NNZs: 816, Bias: -11057772009.030725, T: 2157, Avg. loss: 129899736286163946382032896.000000\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1086278906309.45, NNZs: 816, Bias: -109750855224.427109, T: 2876, Avg. loss: 124044167640363464258486272.000000\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 975206403686.61, NNZs: 816, Bias: -97435829345.468094, T: 3595, Avg. loss: 121739350028261015341236224.000000\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 1213879167830.66, NNZs: 816, Bias: 49403818561.601173, T: 719, Avg. loss: 162232937409192729927221248.000000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1216265231438.25, NNZs: 816, Bias: 94069174837.285843, T: 1438, Avg. loss: 147800586376627553417822208.000000\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-633d8e6e8ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscorefun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \"\"\"\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    503\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m                 for train, test in cv)\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self, func, args, kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \"\"\"\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    980\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                          \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    949\u001b[0m         return self._partial_fit(X, y, alpha, C, loss, learning_rate,\n\u001b[1;32m    950\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                                  coef_init, intercept_init)\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m     def fit(self, X, y, coef_init=None, intercept_init=None,\n",
      "\u001b[0;32m/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, n_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         self._fit_regressor(X, y, alpha, C, loss, learning_rate,\n\u001b[0;32m--> 900\u001b[0;31m                             sample_weight, n_iter)\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_fit_regressor\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, sample_weight, n_iter)\u001b[0m\n\u001b[1;32m   1082\u001b[0m                           \u001b[0mlearning_rate_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m                           intercept_decay)\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/linear_model/sgd_fast.pyx\u001b[0m in \u001b[0;36msklearn.linear_model.sgd_fast.plain_sgd (sklearn/linear_model/sgd_fast.c:4873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msklearn/linear_model/sgd_fast.pyx\u001b[0m in \u001b[0;36msklearn.linear_model.sgd_fast._plain_sgd (sklearn/linear_model/sgd_fast.c:7344)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/Anuar_The_Great/anaconda/lib/python2.7/site-packages/IPython/kernel/zmq/iostream.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IOStream has no fileno.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_socket\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'I/O operation on closed file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search = skgs.GridSearchCV(sgd, param_grid, scoring=scorefun, cv=5)\n",
    "grid_search.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=143.63636363636363, average=False, epsilon=1, eta0=0.01,\n",
      "       fit_intercept=True, l1_ratio=0.7, learning_rate='invscaling',\n",
      "       loss='squared_loss', n_iter=5, penalty='elasticnet', power_t=1,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "-49.3627854097\n",
      "[mean: -11555743628731.87500, std: 1966047021842.49121, params: {'alpha': 10.0, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -2900440596460.37207, std: 306732919411.45886, params: {'alpha': 10.0, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -18709027425.48613, std: 4586088894.89169, params: {'alpha': 10.0, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -1100839.04430, std: 916501.74160, params: {'alpha': 10.0, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -13788089162574.41992, std: 2679359183187.75000, params: {'alpha': 10.0, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -2865762320946.58008, std: 394654548593.80487, params: {'alpha': 10.0, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -34104220548.95659, std: 5101343477.83867, params: {'alpha': 10.0, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -628352536.46478, std: 1116111150.73320, params: {'alpha': 10.0, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -19535217234746.36719, std: 3802836923829.24854, params: {'alpha': 10.0, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -3958042539096.64014, std: 556876581918.86072, params: {'alpha': 10.0, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -74471188047.02789, std: 19396197164.64984, params: {'alpha': 10.0, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -14118468.48965, std: 18624949.13209, params: {'alpha': 10.0, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -13091700652065.58008, std: 2355532363387.52100, params: {'alpha': 10.0, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -2474165814578.37451, std: 533229271457.45203, params: {'alpha': 10.0, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -17095520450.73793, std: 5408298862.17854, params: {'alpha': 10.0, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -6418916.84415, std: 7373792.96991, params: {'alpha': 10.0, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -17847612311149.01172, std: 1915702207146.20752, params: {'alpha': 10.0, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -2813049176165.52686, std: 538373620308.17120, params: {'alpha': 10.0, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -36067697051.08868, std: 6001483581.40422, params: {'alpha': 10.0, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -547381646.42399, std: 1070422737.28934, params: {'alpha': 10.0, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -18869631706939.23438, std: 4468171739969.89258, params: {'alpha': 10.0, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -3161605080568.33447, std: 611568745398.45337, params: {'alpha': 10.0, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -76217032878.78824, std: 5662010420.49231, params: {'alpha': 10.0, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -16660867.39997, std: 32344239.11942, params: {'alpha': 10.0, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -11386204124982.52344, std: 1537983773591.45752, params: {'alpha': 10.0, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -3306831726909.65625, std: 1344041780684.59253, params: {'alpha': 10.0, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -17523591314.28499, std: 1487341637.97640, params: {'alpha': 10.0, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -9822107.04521, std: 7894598.23843, params: {'alpha': 10.0, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -12417402005803.42578, std: 4585528507920.67871, params: {'alpha': 10.0, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -3218312148263.78564, std: 574999989857.92639, params: {'alpha': 10.0, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -33934882171.48511, std: 2688646572.66183, params: {'alpha': 10.0, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -118857015.03700, std: 231975019.24024, params: {'alpha': 10.0, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -14811534405160.12695, std: 2218890343093.64502, params: {'alpha': 10.0, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -3669241154543.18506, std: 600116100180.31348, params: {'alpha': 10.0, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -69065407980.84781, std: 7292399398.92708, params: {'alpha': 10.0, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -15297028.04354, std: 19157846.14825, params: {'alpha': 10.0, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -10727951654010.83789, std: 2643580521487.69189, params: {'alpha': 54.545454545454547, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -2341303255022.70459, std: 817965085003.65125, params: {'alpha': 54.545454545454547, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -1179009034.26590, std: 620435014.80365, params: {'alpha': 54.545454545454547, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -28945826.11505, std: 57242135.15680, params: {'alpha': 54.545454545454547, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -14219211943319.35547, std: 5016688132197.12695, params: {'alpha': 54.545454545454547, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -3460856305338.61182, std: 844295681031.97693, params: {'alpha': 54.545454545454547, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -697210442.86731, std: 314816812.56573, params: {'alpha': 54.545454545454547, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -2644740.02468, std: 4724028.44705, params: {'alpha': 54.545454545454547, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -9689663546665.13281, std: 1061974858296.46509, params: {'alpha': 54.545454545454547, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -2841240196138.07373, std: 839822442814.56238, params: {'alpha': 54.545454545454547, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -1687933245.34664, std: 469030986.66836, params: {'alpha': 54.545454545454547, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -1400374236.48311, std: 2803838658.15355, params: {'alpha': 54.545454545454547, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -14211397162015.26562, std: 9779213612854.15234, params: {'alpha': 54.545454545454547, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -2426381785680.35791, std: 525090173367.75983, params: {'alpha': 54.545454545454547, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -780368459.01016, std: 652020135.93524, params: {'alpha': 54.545454545454547, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -15280.48237, std: 14625.43702, params: {'alpha': 54.545454545454547, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -8922391866908.50977, std: 1068400224073.34705, params: {'alpha': 54.545454545454547, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -3253378436911.83887, std: 1210062918338.66675, params: {'alpha': 54.545454545454547, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -960479751.36789, std: 551413348.65724, params: {'alpha': 54.545454545454547, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -560836.95497, std: 872198.06745, params: {'alpha': 54.545454545454547, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -9963748814689.44531, std: 2733988978831.71387, params: {'alpha': 54.545454545454547, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -2572366877505.80518, std: 587519182914.14563, params: {'alpha': 54.545454545454547, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -2151169715.35336, std: 622244643.13288, params: {'alpha': 54.545454545454547, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -5494744.83556, std: 6448773.99219, params: {'alpha': 54.545454545454547, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -8623506343813.08887, std: 1464774989511.70972, params: {'alpha': 54.545454545454547, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -2848350655954.34912, std: 725317138211.84912, params: {'alpha': 54.545454545454547, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1405443816.18637, std: 890632847.66283, params: {'alpha': 54.545454545454547, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -155922.91034, std: 81933.63128, params: {'alpha': 54.545454545454547, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -11363322682608.09570, std: 4708942736189.64062, params: {'alpha': 54.545454545454547, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -2279144971044.87744, std: 339906350832.79260, params: {'alpha': 54.545454545454547, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -1270994505.97768, std: 708516460.42124, params: {'alpha': 54.545454545454547, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -474886.56406, std: 602032.91419, params: {'alpha': 54.545454545454547, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -10405685352330.26953, std: 2121988606266.74365, params: {'alpha': 54.545454545454547, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -3134951718403.02002, std: 983078058315.00989, params: {'alpha': 54.545454545454547, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -1876968894.73570, std: 583285151.81151, params: {'alpha': 54.545454545454547, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -11307189.03062, std: 22462607.64759, params: {'alpha': 54.545454545454547, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -7152233373716.35059, std: 1426286016546.06030, params: {'alpha': 99.090909090909093, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -1713942012514.76953, std: 358253351808.05243, params: {'alpha': 99.090909090909093, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -1730584978.33443, std: 1353952338.57214, params: {'alpha': 99.090909090909093, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -925831.15770, std: 1821714.57704, params: {'alpha': 99.090909090909093, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -7746664736379.81055, std: 4598078504532.27441, params: {'alpha': 99.090909090909093, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -2685188514545.14648, std: 868498280249.75574, params: {'alpha': 99.090909090909093, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -802610705.42554, std: 751528983.39298, params: {'alpha': 99.090909090909093, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -2311153.40741, std: 3865327.50634, params: {'alpha': 99.090909090909093, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -9817381692771.82617, std: 3035584416110.80322, params: {'alpha': 99.090909090909093, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -2349194821379.61719, std: 615508795851.57544, params: {'alpha': 99.090909090909093, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -1238645478.72699, std: 759217427.08421, params: {'alpha': 99.090909090909093, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -3229762.36454, std: 5483330.93784, params: {'alpha': 99.090909090909093, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -7106789777274.16211, std: 2989698790424.04541, params: {'alpha': 99.090909090909093, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -2360713128055.76025, std: 585333061721.42554, params: {'alpha': 99.090909090909093, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -1314608599.79784, std: 580421761.98193, params: {'alpha': 99.090909090909093, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -957.67780, std: 1179.88526, params: {'alpha': 99.090909090909093, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -7979770572951.45508, std: 2882758138368.42188, params: {'alpha': 99.090909090909093, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -2098328150328.51025, std: 595204199740.29517, params: {'alpha': 99.090909090909093, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -1119517045.15274, std: 1031483829.81854, params: {'alpha': 99.090909090909093, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -1576944.84282, std: 3136240.96101, params: {'alpha': 99.090909090909093, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -10896596879071.48828, std: 3257815970754.69824, params: {'alpha': 99.090909090909093, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -2754723433945.73584, std: 945015707695.87512, params: {'alpha': 99.090909090909093, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -445171474.11676, std: 400027284.62148, params: {'alpha': 99.090909090909093, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -39150331.92290, std: 74255611.45540, params: {'alpha': 99.090909090909093, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -8649881908773.32324, std: 2680210581952.36035, params: {'alpha': 99.090909090909093, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1545180454427.11475, std: 67348272164.75927, params: {'alpha': 99.090909090909093, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1691418916.98162, std: 1100329458.01959, params: {'alpha': 99.090909090909093, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -374509.68219, std: 729017.36757, params: {'alpha': 99.090909090909093, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -9155091381086.81250, std: 2304373795899.11621, params: {'alpha': 99.090909090909093, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -2827507740433.24365, std: 561197552488.56726, params: {'alpha': 99.090909090909093, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -920585749.11050, std: 559649134.92816, params: {'alpha': 99.090909090909093, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -3342.96053, std: 1568.35370, params: {'alpha': 99.090909090909093, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -10375885607089.20508, std: 2288909638949.28516, params: {'alpha': 99.090909090909093, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -2728435904003.24316, std: 494945593188.48907, params: {'alpha': 99.090909090909093, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -1384819754.00222, std: 777310719.55225, params: {'alpha': 99.090909090909093, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -10187984.85563, std: 16448083.36091, params: {'alpha': 99.090909090909093, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -7781417111228.17090, std: 5053383090001.13770, params: {'alpha': 143.63636363636363, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -1261995636764.30762, std: 363712140201.36456, params: {'alpha': 143.63636363636363, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -556408298.99357, std: 447043702.29858, params: {'alpha': 143.63636363636363, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -5710223.62389, std: 11138965.65982, params: {'alpha': 143.63636363636363, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -6094338799694.71973, std: 3466467150553.71240, params: {'alpha': 143.63636363636363, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -2194458527064.05127, std: 678201724626.63611, params: {'alpha': 143.63636363636363, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -703885313.19955, std: 433848550.06505, params: {'alpha': 143.63636363636363, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -334210.43099, std: 490703.76007, params: {'alpha': 143.63636363636363, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -11290560508000.48242, std: 4068407046465.17773, params: {'alpha': 143.63636363636363, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -2436620187210.70508, std: 770055446342.34363, params: {'alpha': 143.63636363636363, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -884439797.80926, std: 810352242.45557, params: {'alpha': 143.63636363636363, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -28077.17673, std: 46734.74761, params: {'alpha': 143.63636363636363, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -8553225791919.41895, std: 3999710720427.24854, params: {'alpha': 143.63636363636363, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -1906944952724.92456, std: 458461169576.09357, params: {'alpha': 143.63636363636363, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -1213787394.07751, std: 928904576.26933, params: {'alpha': 143.63636363636363, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -659.99188, std: 594.10478, params: {'alpha': 143.63636363636363, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -10101859171654.00977, std: 4533670907873.68164, params: {'alpha': 143.63636363636363, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -1345559790914.12231, std: 220771517283.51147, params: {'alpha': 143.63636363636363, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -572415483.23954, std: 549955863.83110, params: {'alpha': 143.63636363636363, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -553.53872, std: 1009.04499, params: {'alpha': 143.63636363636363, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -6780901613066.16504, std: 3902857881683.65723, params: {'alpha': 143.63636363636363, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -2076722709797.52612, std: 1279764033378.33154, params: {'alpha': 143.63636363636363, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -820377193.02456, std: 734730117.15575, params: {'alpha': 143.63636363636363, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -49.36279, std: 3.00677, params: {'alpha': 143.63636363636363, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -9968593270235.67578, std: 3318261483015.37012, params: {'alpha': 143.63636363636363, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1802161714953.12354, std: 757116465505.32654, params: {'alpha': 143.63636363636363, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1046979956.09911, std: 573010379.06045, params: {'alpha': 143.63636363636363, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -560.09912, std: 991.60078, params: {'alpha': 143.63636363636363, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -11495951478551.17188, std: 4202748180353.13184, params: {'alpha': 143.63636363636363, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -2115627532281.97070, std: 625297342182.30042, params: {'alpha': 143.63636363636363, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -1204050365.40749, std: 952511341.08866, params: {'alpha': 143.63636363636363, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -31832.25813, std: 63399.37431, params: {'alpha': 143.63636363636363, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -7404864066319.59180, std: 3617734447980.59668, params: {'alpha': 143.63636363636363, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -2495198634213.94043, std: 1174516843704.73804, params: {'alpha': 143.63636363636363, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -607648242.25203, std: 493171992.14876, params: {'alpha': 143.63636363636363, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -644.19725, std: 810.99603, params: {'alpha': 143.63636363636363, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -8432467095856.57715, std: 4933081342401.72168, params: {'alpha': 188.18181818181819, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -1581636274160.34253, std: 531947114510.13702, params: {'alpha': 188.18181818181819, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -1012223662.91402, std: 355762518.00743, params: {'alpha': 188.18181818181819, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -173.27689, std: 167.42584, params: {'alpha': 188.18181818181819, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -5643657500787.28125, std: 1892448278454.78735, params: {'alpha': 188.18181818181819, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -2063591320747.07715, std: 1134496623521.23096, params: {'alpha': 188.18181818181819, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -861603140.53023, std: 657896212.07946, params: {'alpha': 188.18181818181819, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -12594.97801, std: 25053.10179, params: {'alpha': 188.18181818181819, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -8238461914407.39355, std: 4718675780420.30273, params: {'alpha': 188.18181818181819, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -1562633439830.85938, std: 864622871903.75977, params: {'alpha': 188.18181818181819, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -381349807.75475, std: 667515564.63774, params: {'alpha': 188.18181818181819, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -681.23045, std: 1146.00844, params: {'alpha': 188.18181818181819, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -9415769614205.53906, std: 4091307265530.84619, params: {'alpha': 188.18181818181819, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -2015857346942.00562, std: 929532524249.17102, params: {'alpha': 188.18181818181819, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -1153699975.09580, std: 1129682307.03112, params: {'alpha': 188.18181818181819, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -5525.42321, std: 8760.12999, params: {'alpha': 188.18181818181819, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -6226818840478.63281, std: 4842063609305.59473, params: {'alpha': 188.18181818181819, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -1351568784488.98682, std: 748207593399.47461, params: {'alpha': 188.18181818181819, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -1217806873.23437, std: 627493851.03576, params: {'alpha': 188.18181818181819, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -1077008.39862, std: 2151520.31660, params: {'alpha': 188.18181818181819, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -9884913794935.46875, std: 3745572235684.97119, params: {'alpha': 188.18181818181819, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -2652194146877.60791, std: 1951164849874.70264, params: {'alpha': 188.18181818181819, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -754052803.54083, std: 593821964.52880, params: {'alpha': 188.18181818181819, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -7737283.30063, std: 15543620.64464, params: {'alpha': 188.18181818181819, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -8699499946761.76172, std: 8653914171103.81152, params: {'alpha': 188.18181818181819, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1699189014442.26465, std: 805390018164.10181, params: {'alpha': 188.18181818181819, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1373587488.91241, std: 942637332.32552, params: {'alpha': 188.18181818181819, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -17973807.41886, std: 35906565.49545, params: {'alpha': 188.18181818181819, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -9978203963024.28125, std: 3278143147516.12451, params: {'alpha': 188.18181818181819, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -1507884002464.48218, std: 429909003323.99408, params: {'alpha': 188.18181818181819, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -363687801.24364, std: 579354353.22883, params: {'alpha': 188.18181818181819, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -27912227.08640, std: 55746829.11526, params: {'alpha': 188.18181818181819, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -8963166037251.33203, std: 3688218200878.38086, params: {'alpha': 188.18181818181819, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -1439341576773.04053, std: 793601463058.89136, params: {'alpha': 188.18181818181819, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -888376640.65884, std: 809605514.57552, params: {'alpha': 188.18181818181819, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -239937.87536, std: 477753.38109, params: {'alpha': 188.18181818181819, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -7431387571920.76855, std: 3374831189597.90381, params: {'alpha': 232.72727272727275, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -2254676407371.59277, std: 777460892523.44861, params: {'alpha': 232.72727272727275, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -704627094.41215, std: 613488545.01253, params: {'alpha': 232.72727272727275, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -230185.14007, std: 452656.48931, params: {'alpha': 232.72727272727275, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -3177162699664.44873, std: 2024717386979.15088, params: {'alpha': 232.72727272727275, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -1684091750510.97534, std: 898696565858.29553, params: {'alpha': 232.72727272727275, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -687621696.94774, std: 859649485.35001, params: {'alpha': 232.72727272727275, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -878.14451, std: 1520.72511, params: {'alpha': 232.72727272727275, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -7701776792277.93262, std: 5400770562184.77246, params: {'alpha': 232.72727272727275, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -1147712640727.53760, std: 722961498061.26147, params: {'alpha': 232.72727272727275, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -674329675.71082, std: 709962692.99257, params: {'alpha': 232.72727272727275, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -10502.55390, std: 20989.16068, params: {'alpha': 232.72727272727275, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -6928599768034.01562, std: 3363200622414.47900, params: {'alpha': 232.72727272727275, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -2152307435949.71753, std: 844316140643.14490, params: {'alpha': 232.72727272727275, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -720339031.51983, std: 1030194795.50238, params: {'alpha': 232.72727272727275, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -5802.63612, std: 11489.88931, params: {'alpha': 232.72727272727275, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -10315503519747.58203, std: 5596046725350.11914, params: {'alpha': 232.72727272727275, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -1382723182374.37427, std: 948634883292.82471, params: {'alpha': 232.72727272727275, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -687031049.53269, std: 924457615.05254, params: {'alpha': 232.72727272727275, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -67.82529, std: 13.89300, params: {'alpha': 232.72727272727275, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -2924563933892.59375, std: 2970660832929.10205, params: {'alpha': 232.72727272727275, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -1590006843521.98193, std: 1077542030895.98413, params: {'alpha': 232.72727272727275, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -642494015.44287, std: 821132825.66534, params: {'alpha': 232.72727272727275, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -1121146.54040, std: 2239685.36926, params: {'alpha': 232.72727272727275, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -5046627356936.96582, std: 3858383495087.50732, params: {'alpha': 232.72727272727275, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1076121744419.01416, std: 344062912140.45984, params: {'alpha': 232.72727272727275, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -309482482.40509, std: 254603811.07304, params: {'alpha': 232.72727272727275, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -568.82890, std: 955.35316, params: {'alpha': 232.72727272727275, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -5711564753241.15137, std: 1850036218133.24414, params: {'alpha': 232.72727272727275, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -1411301611231.86914, std: 990680273321.59973, params: {'alpha': 232.72727272727275, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -249897501.27561, std: 305528469.74043, params: {'alpha': 232.72727272727275, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -125502.87764, std: 246300.92631, params: {'alpha': 232.72727272727275, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -8763745861931.08203, std: 4744357172860.16602, params: {'alpha': 232.72727272727275, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -2028290943269.79028, std: 256611953889.77975, params: {'alpha': 232.72727272727275, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -1336529120.07243, std: 898704494.80540, params: {'alpha': 232.72727272727275, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -56649.47874, std: 113061.67549, params: {'alpha': 232.72727272727275, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -1616570667615.41357, std: 1349142874807.81763, params: {'alpha': 277.27272727272725, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -930785140620.59839, std: 820196117874.15918, params: {'alpha': 277.27272727272725, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -285434756.17553, std: 303009300.63977, params: {'alpha': 277.27272727272725, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -91.53671, std: 76.96498, params: {'alpha': 277.27272727272725, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -8303755174074.75391, std: 4006115197384.52686, params: {'alpha': 277.27272727272725, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -1090953879765.15027, std: 963124379160.91895, params: {'alpha': 277.27272727272725, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -786714889.87040, std: 619594987.59210, params: {'alpha': 277.27272727272725, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -99365.30176, std: 196256.89172, params: {'alpha': 277.27272727272725, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -8792263982248.78320, std: 5622922138893.81543, params: {'alpha': 277.27272727272725, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -1893512521000.62573, std: 437061267082.45337, params: {'alpha': 277.27272727272725, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -253520090.41671, std: 241897598.96628, params: {'alpha': 277.27272727272725, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -364.58902, std: 615.07422, params: {'alpha': 277.27272727272725, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -7438341410857.36133, std: 4154334626685.93408, params: {'alpha': 277.27272727272725, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -1267982936434.73267, std: 675194218534.94995, params: {'alpha': 277.27272727272725, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -992646942.66909, std: 744585434.24075, params: {'alpha': 277.27272727272725, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -52.41076, std: 2.19380, params: {'alpha': 277.27272727272725, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -5125534267698.79785, std: 2584623779354.20410, params: {'alpha': 277.27272727272725, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -1550122443036.59619, std: 632694061958.42627, params: {'alpha': 277.27272727272725, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -556163848.81474, std: 563890456.04296, params: {'alpha': 277.27272727272725, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -2340.46912, std: 3565.30844, params: {'alpha': 277.27272727272725, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -10176330555163.54297, std: 5691393154508.92188, params: {'alpha': 277.27272727272725, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -2065504770706.60522, std: 2576448458408.88574, params: {'alpha': 277.27272727272725, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -87452065.76314, std: 113712897.09242, params: {'alpha': 277.27272727272725, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -1575.18682, std: 3030.54267, params: {'alpha': 277.27272727272725, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -8948160020110.62695, std: 3970051038564.76123, params: {'alpha': 277.27272727272725, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1196844328615.23633, std: 668554902834.31494, params: {'alpha': 277.27272727272725, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -869221458.30597, std: 1012827792.80808, params: {'alpha': 277.27272727272725, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -52.38388, std: 3.25316, params: {'alpha': 277.27272727272725, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -5266720676890.12598, std: 3471670315478.47900, params: {'alpha': 277.27272727272725, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -1405927274688.92871, std: 1141439445510.98901, params: {'alpha': 277.27272727272725, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -188749309.44164, std: 285820314.85416, params: {'alpha': 277.27272727272725, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -64.18207, std: 16.20453, params: {'alpha': 277.27272727272725, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -4824873881025.00977, std: 4201939937827.84277, params: {'alpha': 277.27272727272725, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -1423541196107.55225, std: 922316069991.02246, params: {'alpha': 277.27272727272725, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -54.32347, std: 3.47288, params: {'alpha': 277.27272727272725, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -5180317.37140, std: 10349006.03125, params: {'alpha': 277.27272727272725, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -8173595803986.94141, std: 3908993367206.08789, params: {'alpha': 321.81818181818181, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -1077995106674.35767, std: 1255311706146.59863, params: {'alpha': 321.81818181818181, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -425182133.10354, std: 498791114.21966, params: {'alpha': 321.81818181818181, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -91.49641, std: 72.96755, params: {'alpha': 321.81818181818181, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -9416912897809.07812, std: 5285613382691.64941, params: {'alpha': 321.81818181818181, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -614200050725.22229, std: 755834383347.95508, params: {'alpha': 321.81818181818181, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -283457953.70716, std: 406436979.78550, params: {'alpha': 321.81818181818181, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -62.94883, std: 10.61325, params: {'alpha': 321.81818181818181, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -3457716308010.05859, std: 3113163352783.08838, params: {'alpha': 321.81818181818181, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -661813103446.19434, std: 1322155511002.76929, params: {'alpha': 321.81818181818181, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -54.80063, std: 3.02071, params: {'alpha': 321.81818181818181, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -325.87458, std: 334.18173, params: {'alpha': 321.81818181818181, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -4758536015853.11816, std: 3817939138523.24463, params: {'alpha': 321.81818181818181, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -1407494653717.22119, std: 774279573708.13330, params: {'alpha': 321.81818181818181, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -496953299.84522, std: 578385169.23539, params: {'alpha': 321.81818181818181, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -58711.12595, std: 112381.51295, params: {'alpha': 321.81818181818181, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -6413136150279.12012, std: 3352159833646.23584, params: {'alpha': 321.81818181818181, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -986633998967.94287, std: 667133251387.91248, params: {'alpha': 321.81818181818181, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -110103624.07985, std: 219962464.49814, params: {'alpha': 321.81818181818181, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -63.10347, std: 12.15679, params: {'alpha': 321.81818181818181, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -2468862571361.41260, std: 2423870792508.96338, params: {'alpha': 321.81818181818181, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -1670520339197.35962, std: 966548780930.93152, params: {'alpha': 321.81818181818181, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -851943786.87918, std: 1061718305.57947, params: {'alpha': 321.81818181818181, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -175184.18207, std: 221650.09803, params: {'alpha': 321.81818181818181, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -12086717164953.57812, std: 5223712675044.41504, params: {'alpha': 321.81818181818181, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -715380102477.07483, std: 273391121820.05728, params: {'alpha': 321.81818181818181, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -23786215.83391, std: 47519472.88439, params: {'alpha': 321.81818181818181, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -27422.92565, std: 54674.03869, params: {'alpha': 321.81818181818181, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -7583213819604.38672, std: 4744957430686.49316, params: {'alpha': 321.81818181818181, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -1177016696454.44360, std: 610128219890.87671, params: {'alpha': 321.81818181818181, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -619109715.24126, std: 587765761.18030, params: {'alpha': 321.81818181818181, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -56.06604, std: 2.88204, params: {'alpha': 321.81818181818181, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -11557741984034.54688, std: 9187066798577.28711, params: {'alpha': 321.81818181818181, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -700444164474.18542, std: 640600819894.25916, params: {'alpha': 321.81818181818181, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -55.00534, std: 3.22337, params: {'alpha': 321.81818181818181, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -345.89275, std: 572.68266, params: {'alpha': 321.81818181818181, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -6293863957655.31934, std: 4677666218973.99805, params: {'alpha': 366.36363636363637, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -636376006040.01990, std: 533026741974.22974, params: {'alpha': 366.36363636363637, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -261915786.80722, std: 197563547.45740, params: {'alpha': 366.36363636363637, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -69.75288, std: 27.89174, params: {'alpha': 366.36363636363637, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -3226682776896.58740, std: 4919416964703.05078, params: {'alpha': 366.36363636363637, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -1400601332829.91797, std: 1666722047532.80542, params: {'alpha': 366.36363636363637, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -840396651.41306, std: 434667174.51926, params: {'alpha': 366.36363636363637, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -65.53595, std: 16.31475, params: {'alpha': 366.36363636363637, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -3685444776366.37158, std: 2213144038413.14258, params: {'alpha': 366.36363636363637, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -792863636767.98071, std: 709803154490.68396, params: {'alpha': 366.36363636363637, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -431653794.11169, std: 527162020.25264, params: {'alpha': 366.36363636363637, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -59.98131, std: 2.90781, params: {'alpha': 366.36363636363637, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -6439083621677.56934, std: 2329011730978.78271, params: {'alpha': 366.36363636363637, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -1005806659663.36841, std: 642906281556.41638, params: {'alpha': 366.36363636363637, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -163715650.34523, std: 238679885.84124, params: {'alpha': 366.36363636363637, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -709.09218, std: 1306.80658, params: {'alpha': 366.36363636363637, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -6108277533615.18652, std: 6961187720125.49414, params: {'alpha': 366.36363636363637, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -445118969637.31958, std: 640097414448.89868, params: {'alpha': 366.36363636363637, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -370976785.99753, std: 463642561.84439, params: {'alpha': 366.36363636363637, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -247395.01844, std: 477170.52350, params: {'alpha': 366.36363636363637, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -1936765311674.58228, std: 2420675267898.32666, params: {'alpha': 366.36363636363637, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -1231230777546.31812, std: 1551894155273.43384, params: {'alpha': 366.36363636363637, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -54.74379, std: 3.02902, params: {'alpha': 366.36363636363637, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -975.14825, std: 1174.22834, params: {'alpha': 366.36363636363637, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -8345886801605.02344, std: 5323278362586.03320, params: {'alpha': 366.36363636363637, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -635266644586.18579, std: 699963806656.61560, params: {'alpha': 366.36363636363637, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -407407261.27673, std: 226945137.97189, params: {'alpha': 366.36363636363637, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -44012.15476, std: 81744.92318, params: {'alpha': 366.36363636363637, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -2946443178798.94482, std: 3863432537424.50586, params: {'alpha': 366.36363636363637, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -1087092543175.84595, std: 1289677565627.85205, params: {'alpha': 366.36363636363637, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -187563862.98863, std: 374710806.64889, params: {'alpha': 366.36363636363637, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -104.33495, std: 85.44510, params: {'alpha': 366.36363636363637, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -5091562561687.32617, std: 6707993899160.52344, params: {'alpha': 366.36363636363637, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -1122880926636.35962, std: 1019357144383.62170, params: {'alpha': 366.36363636363637, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -52087165.77940, std: 104058470.97399, params: {'alpha': 366.36363636363637, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -794609.75518, std: 1596203.92630, params: {'alpha': 366.36363636363637, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -12175786365342.06836, std: 6350484814275.16797, params: {'alpha': 410.90909090909093, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -789008801401.52563, std: 543638240169.67200, params: {'alpha': 410.90909090909093, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -2152870.66311, std: 4235652.84734, params: {'alpha': 410.90909090909093, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -56.33623, std: 3.01832, params: {'alpha': 410.90909090909093, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -4037835008190.66260, std: 5083593358181.11133, params: {'alpha': 410.90909090909093, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -604226933574.40063, std: 596241132277.39954, params: {'alpha': 410.90909090909093, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -259903256.89485, std: 508103393.23531, params: {'alpha': 410.90909090909093, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -1250308.96893, std: 2497720.52405, params: {'alpha': 410.90909090909093, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -4777721415328.67676, std: 3412951722976.35938, params: {'alpha': 410.90909090909093, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -288126509961.39459, std: 575612738687.05542, params: {'alpha': 410.90909090909093, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -714932975.52839, std: 878365669.75073, params: {'alpha': 410.90909090909093, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -196.74348, std: 274.22717, params: {'alpha': 410.90909090909093, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -3654967692357.44824, std: 3040366483701.45850, params: {'alpha': 410.90909090909093, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -640288786907.86328, std: 621324312266.69360, params: {'alpha': 410.90909090909093, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -164958994.75126, std: 202370109.21758, params: {'alpha': 410.90909090909093, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -4355.91506, std: 8375.54670, params: {'alpha': 410.90909090909093, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -5256564117343.56250, std: 5892984836897.23438, params: {'alpha': 410.90909090909093, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -767289291619.25806, std: 671837983720.84070, params: {'alpha': 410.90909090909093, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -304965337.11008, std: 315852135.18202, params: {'alpha': 410.90909090909093, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -201.55425, std: 283.39411, params: {'alpha': 410.90909090909093, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -7738671320145.39453, std: 7188486532807.65625, params: {'alpha': 410.90909090909093, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -375279996985.20746, std: 749726038315.96875, params: {'alpha': 410.90909090909093, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -360565998.97734, std: 400881875.61535, params: {'alpha': 410.90909090909093, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -255040.25814, std: 509393.67579, params: {'alpha': 410.90909090909093, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -5536839461989.19824, std: 2787222073629.57275, params: {'alpha': 410.90909090909093, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1102113043176.22876, std: 1196935238809.74780, params: {'alpha': 410.90909090909093, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -617024672.20598, std: 668814119.70332, params: {'alpha': 410.90909090909093, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -33290.84319, std: 64964.31216, params: {'alpha': 410.90909090909093, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -14483643556548.42773, std: 7420653557302.12012, params: {'alpha': 410.90909090909093, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -966800405864.09814, std: 1143186133236.15869, params: {'alpha': 410.90909090909093, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -104513429.22762, std: 208794496.91512, params: {'alpha': 410.90909090909093, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -57237.19926, std: 114870.23859, params: {'alpha': 410.90909090909093, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -1330658239685.93628, std: 2658359460955.91162, params: {'alpha': 410.90909090909093, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -1244676023360.01538, std: 736059886801.40845, params: {'alpha': 410.90909090909093, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -607935828.41657, std: 714908454.06705, params: {'alpha': 410.90909090909093, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -117.27574, std: 115.01031, params: {'alpha': 410.90909090909093, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -11375336043508.57812, std: 8889632092400.98242, params: {'alpha': 455.4545454545455, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -506961253228.85547, std: 386647407521.69281, params: {'alpha': 455.4545454545455, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -113664078.56188, std: 222868936.10962, params: {'alpha': 455.4545454545455, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -36594.70431, std: 73404.33151, params: {'alpha': 455.4545454545455, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -7886888869717.26367, std: 6465785882924.04395, params: {'alpha': 455.4545454545455, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -97021882791.28783, std: 193828161293.01685, params: {'alpha': 455.4545454545455, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -122365161.32809, std: 244458289.01372, params: {'alpha': 455.4545454545455, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -58.00367, std: 3.28787, params: {'alpha': 455.4545454545455, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -5818828083319.68750, std: 5038530657765.85254, params: {'alpha': 455.4545454545455, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -220026528966.01675, std: 439564109985.71594, params: {'alpha': 455.4545454545455, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -54.67690, std: 2.97665, params: {'alpha': 455.4545454545455, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -59.89233, std: 2.79980, params: {'alpha': 455.4545454545455, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -5992618143720.95898, std: 4597789858508.23047, params: {'alpha': 455.4545454545455, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -829202824544.82764, std: 1254975920301.32104, params: {'alpha': 455.4545454545455, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -402778533.41602, std: 327283950.99788, params: {'alpha': 455.4545454545455, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -5460.11751, std: 10790.29901, params: {'alpha': 455.4545454545455, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -3768291606734.16357, std: 4873247258847.29590, params: {'alpha': 455.4545454545455, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -965223446231.02637, std: 739831476223.04236, params: {'alpha': 455.4545454545455, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -139271640.80081, std: 257439716.10179, params: {'alpha': 455.4545454545455, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -315.21628, std: 362.87336, params: {'alpha': 455.4545454545455, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -3224806438154.89453, std: 4011748032764.16650, params: {'alpha': 455.4545454545455, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -765915880985.55310, std: 1530129726575.02734, params: {'alpha': 455.4545454545455, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -54.69788, std: 3.03440, params: {'alpha': 455.4545454545455, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -60.23016, std: 2.57196, params: {'alpha': 455.4545454545455, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -12679190878502.86133, std: 3990787916213.60791, params: {'alpha': 455.4545454545455, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1197054173301.97656, std: 725407763455.33081, params: {'alpha': 455.4545454545455, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -323881061.29030, std: 366272275.47278, params: {'alpha': 455.4545454545455, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -396.36955, std: 677.37639, params: {'alpha': 455.4545454545455, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -4715796802239.34473, std: 6970966076654.70508, params: {'alpha': 455.4545454545455, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -517431937446.36731, std: 541816545714.26819, params: {'alpha': 455.4545454545455, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -24502727.55994, std: 48950893.42070, params: {'alpha': 455.4545454545455, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -59.83210, std: 2.81493, params: {'alpha': 455.4545454545455, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -7513683050205.91699, std: 8430192178981.77734, params: {'alpha': 455.4545454545455, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -721035266180.88391, std: 596038525593.49438, params: {'alpha': 455.4545454545455, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -73523529.44105, std: 146883564.19281, params: {'alpha': 455.4545454545455, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -59.98331, std: 2.86201, params: {'alpha': 455.4545454545455, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -4523643333831.72070, std: 3855616737261.01416, params: {'alpha': 500.0, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -781283628246.47131, std: 584100709181.75598, params: {'alpha': 500.0, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -3087052.22286, std: 6167135.84599, params: {'alpha': 500.0, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -58.90308, std: 3.91229, params: {'alpha': 500.0, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 0.1}, mean: -8229644234762.13086, std: 8565183427074.60254, params: {'alpha': 500.0, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -1255891678245.56592, std: 1695998441111.97974, params: {'alpha': 500.0, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -35288729.16166, std: 70498929.75958, params: {'alpha': 500.0, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -59.74916, std: 2.89322, params: {'alpha': 500.0, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 0.1}, mean: -2441441855393.24854, std: 3071265471337.79834, params: {'alpha': 500.0, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -786125998887.27271, std: 998073495072.90173, params: {'alpha': 500.0, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -64238232.37721, std: 128333601.95374, params: {'alpha': 500.0, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -2358.19970, std: 4618.95949, params: {'alpha': 500.0, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 0.1}, mean: -16952826327310.38086, std: 6243393685845.04297, params: {'alpha': 500.0, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -622486848365.39575, std: 633315779191.62305, params: {'alpha': 500.0, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -125756892.99185, std: 247896171.27913, params: {'alpha': 500.0, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -3820.65822, std: 7311.18151, params: {'alpha': 500.0, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 1}, mean: -2119064316280.60474, std: 3511619970695.70752, params: {'alpha': 500.0, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -77291645887.78992, std: 154411532457.52972, params: {'alpha': 500.0, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -54.96541, std: 3.33598, params: {'alpha': 500.0, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -60.69886, std: 2.35997, params: {'alpha': 500.0, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 1}, mean: -4410804409216.18652, std: 4775544627408.75684, params: {'alpha': 500.0, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -312784297995.52069, std: 624873519667.70203, params: {'alpha': 500.0, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -4225748.19405, std: 8441994.81897, params: {'alpha': 500.0, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -59.96607, std: 2.82082, params: {'alpha': 500.0, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 1}, mean: -7898765053150.98242, std: 3248771828248.72363, params: {'alpha': 500.0, 'power_t': 0.1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -1375448428909.77417, std: 1013707757623.64282, params: {'alpha': 500.0, 'power_t': 0.3, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -54.12714, std: 2.39712, params: {'alpha': 500.0, 'power_t': 0.6, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -59.45358, std: 1.91996, params: {'alpha': 500.0, 'power_t': 1, 'l1_ratio': 0.3, 'epsilon': 10}, mean: -7529051085369.00977, std: 6912984017153.92285, params: {'alpha': 500.0, 'power_t': 0.1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -1061191077698.35657, std: 946128228527.84973, params: {'alpha': 500.0, 'power_t': 0.3, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -407927835.69101, std: 344284705.51524, params: {'alpha': 500.0, 'power_t': 0.6, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -89.33713, std: 58.57130, params: {'alpha': 500.0, 'power_t': 1, 'l1_ratio': 0.5, 'epsilon': 10}, mean: -1347363513537.80786, std: 2691732885828.73242, params: {'alpha': 500.0, 'power_t': 0.1, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -313997806350.53912, std: 386757661064.63074, params: {'alpha': 500.0, 'power_t': 0.3, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -285077450.05645, std: 572702970.73874, params: {'alpha': 500.0, 'power_t': 0.6, 'l1_ratio': 0.7, 'epsilon': 10}, mean: -80.84736, std: 41.96989, params: {'alpha': 500.0, 'power_t': 1, 'l1_ratio': 0.7, 'epsilon': 10}]\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.104764922\n",
      "31.5408681897\n",
      "31.0087913208\n",
      "29.7959211623\n",
      "29.1762850838\n",
      "28.7031597255\n",
      "28.3851103564\n",
      "27.9664647564\n",
      "27.6934389404\n",
      "27.3513602572\n",
      "26.8900999851\n",
      "26.8946147621\n",
      "28.1223162366\n"
     ]
    }
   ],
   "source": [
    "# Iteration through the list of alphas and generation of accuracy from the testing set\n",
    "alpha_list = [1, 5, 10, 30, 50, 75, 100, 150, 200, 300, 750, 1000, 3000]\n",
    "scores_df = pd.DataFrame(alpha_list, columns=['alphas'])\n",
    "scores_df['values'] = 1\n",
    "for i, alpha_num in enumerate(alpha_list):\n",
    "    lr = Ridge(alpha=alpha_num, tol=0.001, solver='auto')\n",
    "    #lr.fit(X, Y)\n",
    "    #Xtrain, Xtest, Ytrain, Ytest = skcv.train_test_split(X, Y, train_size=0.70)\n",
    "    scores = skcv.cross_val_score(lr, X, Y, scoring=scorefun, cv=10)\n",
    "    fn_score = np.mean(scores)\n",
    "    print(fn_score)\n",
    "    scores_df.iloc[i, 1] = fn_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqMAAAH+CAYAAACoZwfcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xl0VPX9//HXTDJJhiwmQxKMIEuECeCCCkX4KTvi/tU2\nX6u1CFgdBdqvWrvg1pbWbra21fbUCvmKCFoXjBGLlrqAAexXioAoiwQpi4JRSCLZSMgkn98fnEwd\nQ0JuDPO5kOfjnJzD3Jm5856XN/Dyzr13PMYYIwAAAMACr+0BAAAA0HVRRgEAAGANZRQAAADWUEYB\nAABgDWUUAAAA1lBGAQAAYA1lFIAV7733noYPHy6/36/c3NyYv/4bb7whr9ervXv3xvy1nerIrMfT\n+wPQtVFGgeOI1+tt8+fLlrr+/fvrpz/9aSdN27Yf/vCHSk9P19atW7VmzZqYvObnnX/++SotLVVO\nTk7MXxtH9/Of/1z9+vU76uN27twZ2f43btzY4v5zzjlHXq9Xv/jFLyLLysrKdOuttyo3N1dJSUnK\nzs7W6NGj9fTTT0ceM23atCP+jqWlpXXOGwQQEW97AADtV1paGvnzm2++qfz8fK1fvz5SqOLi4r7U\n+j0ez5d6vhMffPCBpk6dqt69e8fsNZuFw2H5fD5lZ2fH/LXRNmOMwuGw4+f16dNHBQUFeuihhyLL\n/vWvf+mDDz5QZmZm1Ladn5+vyspKzZ07V3l5edq3b59Wr16t8vLyqHWOHj1azz77bNQyr5d9OEBn\n47cKOI5kZ2dHfjIyMiRJWVlZkWU7d+7UpEmTlJqaquzsbOXn52v37t2R53/00UfKz89XVlaW/H6/\nTjvtND3wwAOSpLFjx2r79u366U9/GtkLtHv3bjU0NOiOO+7QqaeeqqSkJJ1yyin6xje+0eacH3/8\nsa699lplZGSoW7duGjdunNauXSvpP3uytm/frh//+Mfyer362c9+1mId27Ztk9fr1f/93/9FLV+9\nenXk+ZL00EMP6ZxzzlFqaqpycnL0jW98I6q0N39c/fLLL+uCCy6Q3+/Xo48+esSPsd966y2NHj1a\n3bp1UyAQ0De/+U3t27cvcv/s2bM1YMCAqHlWrVoVyUqSKisrdcMNNygnJ0dJSUnq3bu3vve977WZ\n1z333KPBgwcrOTlZvXv31owZM1RZWdnq45tnX7JkSeRQhzPPPFPLly9v8djNmzdr9OjRSk5O1umn\nn66lS5c6em2n7+f666/X5MmTI7cfe+wxeb1ePfroo5Fl3/zmN3XddddJkubPny+fz6c33nhD55xz\njpKSkvToo4/qxz/+sXbt2hXZFo+0jXzet771LT3xxBOqr6+PLJs7d66uueYaJScnR5Z99tlnWrFi\nhX7+859r4sSJOvXUU3XuuedqxowZmjlzZtQ6ExISon7nsrOzlZmZ2eYcAJyjjAIniM2bN2vs2LE6\n//zztXbtWi1fvlxxcXG68MILI/9Az5w5U1VVVXr99de1detWPfroo+rVq5ckqaioSH379tX3v/99\nlZaWqrS0VL169dKf/vQnLVq0SE8++aQ++OADvfjiixo5cmSrcxhjdNVVV6mkpEQvvfSS/vWvf6lH\njx668MILVVZWpt69e+vjjz9Wr169dOedd6q0tPSI5WbAgAEaOXKkFi5cGLX88ccf1//7f/9Pp512\nmqTDe3N/97vfaePGjSoqKtLu3bt17bXXtljf9773Pd111116//33dfnll7e4v7S0VJMmTVLv3r21\nZs0a/e1vf9PGjRv13//931GPO9re43vvvVfr16/Xiy++qA8++EDPPPOMBg8e3OZzunXrpoKCAm3Z\nskXz58/XG2+8oVtvvbXN50jSHXfcodmzZ+udd97ReeedpyuuuCKqiEvS97//fd1777169913dd55\n5+maa67RZ5991u7Xdvp+xo8fH1WKly1bpqysLC1btiyy7I033tCECRMit5uamnTnnXfqwQcf1Nat\nW3X55Zdr1qxZ6tWrV2RbPFqhHzdunDIzM/Xcc89JkqqqqvTMM88oFApFPS4lJUWpqal64YUXVFtb\n2+Y6+bZsIEYMgOPS8uXLjcfjMXv27DHGGDN16lRz7bXXRj2mrq7OdOvWzSxevNgYY8yQIUPM7Nmz\nW11n//79zU9/+tOoZbfddpsZP358u+d67bXXjMfjMVu2bIksq6+vNzk5OeZnP/tZZFnfvn3NL37x\nizbX9cgjj5hAIGAOHToUWU8gEDBz585t9Tnr1q0zHo/H7N271xjzn5yeeOKJqMd9Mb97773XnHrq\nqaahoSHymA0bNhiPx2NWrlxpjDHmJz/5ienfv3/UelauXGk8Ho/ZtWuXMcaYK6+80kybNq3N93U0\nzz//vElMTGx11ubb8+bNizwmHA6bPn36mB/96EdRjykqKoo85pNPPjEej8e88sor7X5tp+9nx44d\nUf/9e/XqZX73u9+ZnJwcY4wxmzdvNh6Px/z73/82xhjz2GOPGY/HY1atWhW1nvvuu8/07du33a+3\natUq85vf/MaMGTPGGGPMX/7yFzNkyBBjTMttraioyGRmZpqEhAQzbNgwc9ttt5lly5ZFrXfq1Kkm\nPj7epKSkRP3813/9V7uzANA+7BkFThBr1qxRUVGRUlNTIz+ZmZmqr6/Xtm3bJEm33367fvnLX2rE\niBG68847tXLlyqOu94YbbtB7772n/v37a8aMGXr++efV0NDQ6uM3bdqk7t27a+DAgZFlCQkJOu+8\n87Rp0yZH7+nrX/+6amtrtWTJEknSkiVLVFtbq2uuuSbymDfeeEMXXXSRevfurbS0NI0aNUqStGvX\nrqh1DR8+vM3X2rRpk0aMGKH4+P8cSn/WWWfppJNOcjT3zJkz9dxzz+nMM8/U7bffrqVLlx51D9vz\nzz+v0aNHq2fPnkpNTdXkyZPV0NDQYi/nF31+D3VcXJyGDx/eYtazzz478ufs7GzFxcXpk08+afdr\nO30/ffv2Vd++fSN73z/77DPNnDlTtbW12rJli5YtW6Y+ffq0ODnpK1/5Spvv9Wg8Ho+mTZumt956\nSyUlJSooKGixV7TZVVddpT179mjp0qXKz8/X5s2bNWHCBH3nO9+JetyIESO0YcOGqJ85c+Z8qTkB\ntEQZBU4QxhhNmTKlxT+eJSUluvHGGyUdPkN4165dmj59uj7++GNdcskluv7669tc75AhQ7Rjxw49\n8MADSkhI0G233aazzz5bVVVVjudzeoJURkaGrrjiCi1YsECStGDBAl155ZWRM5p3796tSy+9VLm5\nuXrmmWe0du1avfjii5KkQ4cORa3r88cNHonH4zlqafR6vS0e88ViPmnSJO3evVv33HOP6urqNHny\nZI0fP15NTU1HXOfq1av19a9/XWPHjtULL7yg9evX65FHHpExpsV7OJojZZyQkNDicc2ztOe1nb4f\n6fBH9a+//rqWL1+uUaNGKSkpSaNHj9ayZcu0bNkyjR8/PurxcXFxR5zTqaysLF155ZWaOXOm3n//\n/Ta37YSEBI0bN0533nmnXnnlFd133316+OGHo46xTkpKUm5ubtTPySef/KXnBBCNMgqcIIYNG6YN\nGza0+MczNzdX6enpkcedfPLJmjZtmh5//HH97//+r5588klVV1dLOvwPdGNjY4t1Jycn66qrrtJD\nDz2kt99+W1u2bNGKFSuOOMfpp5+usrIybdmyJbKsvr5eq1ev1hlnnOH4fU2dOlUvv/yySkpK9Pe/\n/11TpkyJ3LdmzRrV1dXpwQcf1MiRIzVgwICj7k1szemnn6633norqlxu2LBBBw4ciMydnZ2tTz/9\nNKqIrVu3rsW6MjIydO211+qRRx7RSy+9pOLi4qg8Pm/VqlXKzMzUz372M33lK19R//799eGHH7Zr\n5s+f3BUOh/Wvf/3rqMenduS1nbwf6fDxm8XFxXrttdcix4aOHz9er732moqLi1uU0SNpbVs8mltu\nuUXLli3T1Vdf7egyTM178j9/wlosry4BdGVc2gk4Qdx9990aPny4Jk+erNtuu02ZmZnauXOnFi9e\nrNtuu039+vXTd77zHV122WUKBoOqq6vT888/r969eyslJUWS1K9fP61atUoffvih/H6/unfvrgce\neEA9e/bUkCFD1K1bNz311FOKj49XMBg84hwTJkzQ8OHDdd111+nPf/6z0tLSdN999+nQoUOaMWNG\n5HFH2wvZ7OKLL1ZGRoauueYaBQIBXXzxxZH7gsGgPB6PHnjgAV133XXasGGD7rvvvg7l953vfEcP\nPfSQpk2bprvvvlsVFRWaOXOmRo8erfPPP1/S4UJVW1urH//4x7rhhhu0bt06Pfzww1HrueeeezRs\n2DANHjxYXq9XTzzxhFJTU1u9hNXAgQO1b98+zZs3T2PHjtWqVav0l7/8pV0z33///Tr55JPVt29f\n/f73v1dZWVmLM8Lb0p7Xdvp+pMM5VVRU6MUXX9Q999wTWfaDH/xATU1N7Sqjubm5Ki0t1VtvvaX+\n/fsrOTlZfr//qM8bP3689u/fH7Un/PPbWllZmfLz8/Wtb31LZ511ltLT07Vx40bdddddys3NjTqs\nob6+Xp988kmLbZW9o0Ans3OoKoAva/ny5cbr9UZOajHGmPfee89ceeWVJiMjw/j9ftO/f39zyy23\nmIqKCmOMMd/+9rdNMBg0fr/fdO/e3Vx++eVm8+bNkee//fbb5txzzzV+v994vV6zc+dOM2fOHDN0\n6FCTlpZmUlJSzPDhw82LL77Y5mwff/yxufbaa016errx+/1m7NixZu3atVGPac8JTM2++93vGq/X\na+64444W9/35z382p556qvH7/WbUqFFm6dKlxuv1muLi4lZzam35W2+9ZUaPHm38fr9JT0833/zm\nN82+ffuinjdv3jyTm5tr/H6/ufTSS83TTz9tvF5v5ASm++67z5xxxhkmJSXFnHTSSWbs2LHmzTff\nbPP9/ehHPzI9evQwycnJ5rLLLjNPPfVU1Dq/OGvzyUl/+9vfzNChQ01iYqI5/fTTzWuvvdbm+zPG\nmPj4ePP444+3+7U78n6MMSYvL8907949allWVpYZOHBg1LLHHnvM+Hy+Fs9vaGgw1113nQkEAsbj\n8bQ4sa7Zjh07jNfrbXOmz29r9fX15u677zbDhw83gUDA+P1+k5uba2bMmGE++uijyHOmTZtmPB5P\nix+v12vKysqO+v4BtJ/HmGN/7YqGhgbNnz9f4XBYjY2NGjhwoCZOnKhly5Zp69atkg5fXuSqq67S\nSSeddKzHAYDj2htvvKHx48fro48+0imnnGJ7HAD4UmJSRqXDJxM0HwM0b948TZo0SSeffLISExMl\nHT6QvrS0VFdeeWUsxgGA4xZlFMCJJGYnMDWfKdnY2ChjjPx+f6SISofLardu3WI1DgAc1zi5BsCJ\nImZ7RpuamjRnzhxVVFRo2LBhmjRpkiTp9ddf14YNG+Tz+XTTTTdFDlCvrKyMnOHbLCUlxdHZkQAA\nAHC3mJXRZnV1dVq4cKEmTpwYddHjlStXqqysTFdddZUkafny5SouLo567pgxYzRu3LhYjgsAAIBj\nKOaXdkpKSlIwGNTevXujyuiZZ56pJ598MnJ76NChysvLi3puSkqKKioqFA6HYzZveyQmJka++9st\n4uPjlZGR4cq8JDJzyo15SWTmlJvzksisI8jMGTfmJZGZU815ddr6Om1NbaipqZHX65Xf71dDQ4O2\nb9+usWPHqqysTN27d5ckbd26VTk5OZHnpKWlHfEj+X379rX5VYQ2xMfHu26mZuFw2JWzkZkzbs5L\nIjOn3JiXRGYdQWbOuDkvicxsiUkZra6uVlFRkYwxMsZoyJAhka/vKysrk8fjUSAQ0GWXXRaLcQAA\nAOASMSmjPXr00PTp01ssv+aaa2Lx8gAAAHApvpseAAAA1lBGAQAAYA1lFAAAANZQRgEAAGANZRQA\nAADWUEYBAABgDWUUAAAA1lBGAQAAYA1lFAAAANZQRgEAAGANZRQAAADWUEYBAABgDWUUAAAA1lBG\nAQAAYA1lFAAAANZQRgEAAGANZRQAAADWUEYBAABgDWUUAAAA1lBGAQAAYA1lFAAAANZQRgEAAGAN\nZRQAAADWUEYBAABgDWUUAAAA1lBGAQAAYA1lFAAAANZ4jDHG9hDtVVdXp7q6OrltZK/Xq6amJttj\nRPF4PEpISNChQ4dcl5dEZk65MS+JzJxyc14SmXUEmTnjxrwkMnPK4/EoPT2909YX32lrioGkpCRV\nVVWpoaHB9ihR/H6/Dh48aHuMKD6fT+np6aqpqXFdXhKZOeXGvCQyc8rNeUlk1hFk5owb85LIzCmf\nz9ep6+NjegAAAFhDGQUAAIA1lFEAAABYQxkFAACANZRRAAAAWEMZBQAAgDWUUQAAAFhDGQUAAIA1\nlFEAAABYQxkFAACANZRRAAAAWEMZBQAAgDWUUQAAAFhDGQUAAIA1lFEAAABYQxkFAACANZRRAAAA\nWEMZBQAAgDWUUQAAAFhDGQUAAIA18bYHQOcrLy/XvHnz1K1bN02ePFlpaWm2RwIAADgiyugJpry8\nXPn5+SopKZEkLVq0SIWFhQoEApYnAwAAaImP6U8wBQUFkSIqSSUlJSooKLA4EQAAQOsoowAAALCG\nMnqCCYVCCgaDkdvBYFChUMjiRAAAAK3jmNETTCAQUGFhIScwAQCA40LMymhDQ4Pmz5+vcDisxsZG\nDRw4UBMnTtQrr7yikpISxcXFKSMjQ1dddZWSkpJiNdYJKRAI6K677lJWVpb27dunhoYG2yMBAAAc\nUczKqM/n09SpU5WQkKDGxkbNmzdPu3bt0mmnnaaJEyfK6/Xq1Vdf1cqVK3XhhRfGaiwAAABYFNNj\nRhMSEiRJjY2NMsbI7/frtNNOk9d7eIxevXqpsrIyliMBAADAopgeM9rU1KQ5c+aooqJCw4YNU3Z2\ndtT969ev1xlnnCFJqqysVHV1ddT9KSkpio9332GucXFx8vl8tseI0pyTG/OSyMwpN+YlkZlTbs5L\nIrOOIDNn3JiXRGZOdXZOHmOM6dQ1tkNdXZ0WLlyoiRMnql+/fpKkFStW6OOPP9Y111wjSVq+fLmK\ni4ujnjdmzBiNGzcu1uMCAADgGLFSRiWpuLhY8fHxOv/887V+/XqtW7dOU6ZMibT/1vaMNjY2KhwO\n2xi5VYmJiaqvr7c9RpT4+HhlZGSooqLCdXlJZOaUG/OSyMwpN+clkVlHkJkzbsxLIjOnmvPqtPV1\n2pqOoqamRl6vV36/Xw0NDdq+fbvGjh2rbdu26Z///KemTZsWtRs6LS3tiJckcuPZ4fHx8a6bqVk4\nHHblbGTmjJvzksjMKTfmJZFZR5CZM27OSyIzW2JWRqurq1VUVCRjjIwxGjJkiHJzc/XHP/5RjY2N\nWrhwoaTDJzFdfvnlsRoLAAAAFsWsjPbo0UPTp09vsfzWW2+N1QgAAABwGb4OFAAAANZQRgEAAGAN\nZRQAAADWUEYBAABgDWUUAAAA1lBGAQAAYA1lFAAAANZQRgEAAGANZRQAAADWUEYBAABgDWUUAAAA\n1lBGAQAAYA1lFAAAANZQRgEAAGANZRQAAADWUEYBAABgDWUUAAAA1lBGAQAAYA1lFAAAANZQRgEA\nAGANZRQAAADWxNseAMdGWVmZHnroIdXW1upb3/qWAoGA7ZEAAABaoIyegMrLy5Wfn6+SkhJJ0ksv\nvaTCwkIKKQAAcB0+pj8BFRQURIqoJJWUlKigoMDiRAAAAEdGGQUAAIA1lNETUCgUUjAYjNwOBoMK\nhUIWJwIAADgyjhk9AQUCAS1evFhPPPEEJzABAABX8xhjjO0h2quurk51dXVy28her1dNTU22x4ji\n8XiUkJCgQ4cOuS4vicyccmNeEpk55ea8JDLrCDJzxo15SWTmlMfjUXp6eqet77jaM5qUlKSqqio1\nNDTYHiWK3+/XwYMHbY8RxefzKT09XTU1Na7LSyIzp9yYl0RmTrk5L4nMOoLMnHFjXhKZOeXz+Tp1\nfRwzCgAAAGsoowAAALCGMgoAAABrKKMAAACwhjIKAAAAayijAAAAsIYyCgAAAGsoowAAALCGMgoA\nAABrKKMAAACwhjIKAAAAayijAAAAsIYyCgAAAGsoowAAALCGMgoAAABrKKMAAACwhjIKAAAAayij\nAAAAsIYyCgAAAGsoowAAALCGMgoAAABrKKMAAACwhjIKAAAAayijAAAAsIYyCgAAAGsoowAAALAm\nPhYv0tDQoPnz5yscDquxsVEDBw7UxIkTtWnTJr3xxhvav3+/QqGQTjnllFiM02Xs379fv/rVr9TY\n2KhQKKRAIGB7JAAAgCgxKaM+n09Tp05VQkKCGhsbNW/ePO3atUvZ2dm65pprtGTJkliM0aWUlZUp\nPz9fmzdvliQtXbpUhYWFFFIAAOAqMfuYPiEhQZLU2NgoY4z8fr+ysrKUmZkZqxG6lLlz50aKqCSV\nlJSooKDA4kQAAAAtxWTPqCQ1NTVpzpw5qqio0LBhw5Sdnd3m4ysrK1VdXR21LCUlRfHxMRu53eLi\n4uTz+WyPEcXj8bRY5qY53TRLs+Zti22s/cjMGTfnJZFZR5CZM27MSyIzpzo7J48xxnTqGo+irq5O\nCxcu1MSJE9WvXz9J0vz58zVp0qSoY0aXL1+u4uLiqOeOGTNG48aNi+W4x639+/drzJgxkb2jgwcP\nVnFxMXuiAQCAq8T8fwGSkpIUDAa1d+/eSBk9kqFDhyovLy9qWUpKiioqKhQOh4/1mI4kJiaqvr7e\n9hhR4uPjVVxcrF/96lcyxujmm2+WMUb79u2zPZok92aWkZHBNuYAmTnj5rwkMusIMnPGjXlJZOZU\nc16dtr5OW1Mbampq5PV65ff71dDQoO3bt2vs2LFtPictLU1paWktlu/bt08NDQ3HaNKOiY+Pd91M\nkpSVlaU777wzMpubZnRrZpIUDoddN5ub85LIzCk35iWRWUeQmTNuzksiM1tiUkarq6tVVFQkY4yM\nMRoyZIhyc3O1ZcsW/f3vf1dtba2efPJJ5eTkaPLkybEYCQAAAC4QkzLao0cPTZ8+vcXyQYMGadCg\nQbEYAQAAAC7ENzABAADAGsooAAAArKGMAgAAwBrKKAAAAKyhjAIAAMAayigAAACsoYwCAADAGsoo\nAAAArKGMAgAAwBrKKAAAAKyhjAIAAMAayigAAACsoYwCAADAGsooAAAArKGMAgAAwBrKKAAAAKyh\njAIAAMAayigAAACsoYwCAADAGsooAAAArKGMAgAAwBrKKAAAAKyhjAIAAMAayigAAACsoYwCAADA\nGsooAAAArKGMAgAAwBqPMcbYHqK96urqVFdXJ7eN7PV61dTUZHuMKB6PRwkJCTp06JDr8pLIzCk3\n5iWRmVNuzksis44gM2fcmJdEZk55PB6lp6d32vriO21NMZCUlKSqqio1NDTYHiWK3+/XwYMHbY8R\nxefzKT09XTU1Na7LSyIzp9yYl0RmTrk5L4nMOoLMnHFjXhKZOeXz+Tp1fXxMDwAAAGsoowAAALCG\nMgoAAABrKKMAAACwhjIKAAAAayijAAAAsIYyCgAAAGsoowAAALCGMgoAAABrKKMAAACwhjIKAAAA\nayijAAAAsIYyCgAAAGsoowAAALCGMgoAAABrKKMAAACwhjIKAAAAayijAAAAsIYyCgAAAGsoowAA\nALCGMgoAAABrKKMAAACwhjIKAAAAayijAAAAsIYyCgAAAGsoowAAALAmPhYv0tDQoPnz5yscDqux\nsVEDBw7UxIkTVVtbq+eee06fffaZ0tPTdfXVV8vv98diJAAAALhATMqoz+fT1KlTlZCQoMbGRs2b\nN0+7du3S1q1blZubqwsuuECrVq3SqlWrdOGFF8ZiJAAAALhAzD6mT0hIkCQ1NjbKGCO/36+tW7fq\n7LPPliQNGTJE77//fqzGAQAAgAvEZM+oJDU1NWnOnDmqqKjQsGHDlJ2drZqaGqWkpEiSUlJSVFNT\nE3l8ZWWlqquro9aRkpKi+PiYjdxucXFx8vl8tseI0pyTG/OSyMwpN+YlkZlTbs5LIrOOIDNn3JiX\nRGZOdXZOMUvd6/VqxowZqqur08KFC7Vjx46o+z0eT9TttWvXqri4OGrZmDFjNG7cuGM+64kkIyPD\n9gjHHTJzjsycIS/nyMw5MnOOzOxos4yWlpbq5JNPbvX+tWvXaujQoY5eMCkpScFgUHv37lVycrKq\nqqqUmpqqqqoqJScnRx43dOhQ5eXlRT03JSVFFRUVCofDjl7zWEtMTFR9fb3tMaLEx8crIyPDlXlJ\nZOaUG/OSyMwpN+clkVlHkJkzbsxLIjOnmvPqtPW1dWcwGFRlZWXk9oABA7Rt27bI7bFjx6qqquqo\nL1JTUyOv1yu/36+GhgZt375dY8eOVV5enjZs2KALLrhA77zzjgYOHBh5TlpamtLS0lqsa9++fWpo\naGjXm4uV+Ph4183ULBwOu3I2MnPGzXlJZOaUG/OSyKwjyMwZN+clkZktbZZRY0zU7f3793foRaqr\nq1VUVCRjjIwxGjJkiHJzc3XyySdr0aJFWrduXeTSTgAAAOg6YnLMaI8ePTR9+vQWy7t166apU6fG\nYgQAAAC4EN/ABAAAAGva3DNaW1ur0aNHRz6ur66u1qhRoyL3Hzx48NhOBwAAgBNam2X00Ucfjbp9\n4403Rt2+6aabOn8iAAAAdBltltFp06bFaAwAAAB0RW0eM/r222/rvffei9z+9NNPdd111+mss87S\nLbfc0uIbkgAAAAAn2iyjt99+u0pLSyO3Q6GQtm3bpptvvlkbN27UD37wg2M+IDpHeXm57r//ft1/\n//0qLy+3PQ4AAICko3xMv2XLlsgJSxUVFXr55Ze1ceNG5eXl6corr9TIkSP1l7/8JSaDouPKy8uV\nn5+vkpISSdLSpUtVWFioQCBgeTIAANDVtblntLGxUYmJiZKk1atX6+STT458Reepp56qzz777NhP\niC+toKAgUkQlqaSkRAUFBRYnAgAAOKzNMjp48GA9++yzkqSnn35aEydOjNy3Z88epaenH9vpAAAA\ncEJrs4yycPMTAAAgAElEQVT+5je/0S233KKMjAwtWbJEs2bNitz3zDPP6Pzzzz/mA+LLC4VCCgaD\nkdvBYFChUMjiRAAAAIe1eczoBRdcoN27d6ukpETBYFBpaWmR+y699FJde+21x3xAfHmBQECFhYWR\nj+ZDoRDHiwIAAFc46nfTp6WladiwYS2WDxw48JgMhGMjEAhE7dkGAABwgzbLaL9+/eTxeCJfB/pF\nHo9H//73v4/JYAAAADjxtVlG9+zZo9zcXE2ZMkXnnXeeJLVaTAEAAACn2iyje/fu1V//+lctXLhQ\nCxcu1JQpU3T99derV69esZoPAAAAJ7A2z6bPzMzUrbfeqjVr1qiwsFAHDhzQBRdcoAkTJmjHjh2x\nmhEAAAAnqDbL6OcNGjRI48eP18iRI/X222+roqLiWM4FAACALuCoZXTTpk364Q9/qD59+ui3v/2t\nLr30Uu3du1fnnntuLOYDAADACazNY0bPPfdcHTx4UNdff71WrlypXr16yePxSJKampokSV5vu3eu\nAgAAAFHabJLvvPOOtm7dqnvvvVf9+vWTz+dTfHx85Mfn88VqTgAAAJyA2twzyjVEAQAAcCy1WUb7\n9u0bozEAAADQFXHAJwAAAKyhjAIAAMAayigAAACsoYwCAADAmlZPYBo1atRRn+zxeLRixYpOHQgA\nAABdR6tl9MYbbzzqk5svgB8rdXV1kWuduonX65Xf77c9RhSPx6Pa2lpX5iWRmVNuzEsiM6fcnJdE\nZh1BZs64MS+JzJzq7P7XauLTpk3r1BfqDElJSaqqqlJDQ4PtUaL4/X4dPHjQ9hhRfD6f0tPTVVNT\n47q8JDJzyo15SWTmlJvzksisI8jMGTfmJZGZU539pUftOma0qalJc+fO1fjx43XmmWdKklasWKFn\nn322U4cBAABA19KuMvqTn/xEjz76qEKhkHbv3i1J6tmzp379618f0+EAAABwYmtXGX3ssce0ZMkS\nfeMb35DXe/gp/fr14+tCAQAA8KW0+2P6lJSUqGU1NTVKTU09JkMBAACga2hXGb3kkkt0xx13qK6u\nTtLhcvqjH/1IV1xxxTEdDgAAACe2dpXR3//+9yotLVV6eroqKyuVkpKinTt3cswoAAAAvpR2XUzr\npJNOUlFRkT755BPt2rVLp556qnJyco71bAAAADjBtVpGm5qaWizLyspSVlZW1P3NJzQBAAAATrVa\nRr/4DQQej0fGmBbLGhsbj81kAAAAOOG1WkY/f9mml156Sc8995zuvvtu9e7dW7t379avf/1r5efn\nx2RIAAAAnJhaLaN9+/aN/Pn3v/+93n77bWVkZEiS8vLyNGzYMA0bNkwzZ8485kMCAADgxNSuAz4r\nKytVW1sbtay2tlYHDhw4JkMBAACga2jX2fRTp07VxIkT9d3vflennnqqdu/erT/+8Y+aMmXKsZ4P\nAAAAJ7B2ldHf/OY36t+/v55++ml9/PHHysnJ0f/8z/8oFAod6/kAAABwAmtXGfV6vZo+fbqmT59+\nrOcBAABAF9KuY0aNMZo3b57GjRunYDCo8ePHa968eS0u9YTjQ3l5ue6//37df//9Ki8vtz0OAADo\nwtq1Z/SXv/ylFixYoO9973uRSzv99re/1d69e3Xvvfce6xnRicrLy5Wfn6+SkhJJ0tKlS1VYWKhA\nIGB5MgAA0BW1q4wWFBSouLhYffr0iSy76KKLNGrUKMrocaagoCBSRCWppKREBQUFmjVrlsWpAABA\nV9Wuj+lra2uVmZkZtax79+6qq6s7JkMBAACga2hXGb344os1efJkvf/++zp48KC2bNmiKVOm6KKL\nLjrW86GThUIhBYPByO1gMMhVEQAAgDXtKqN/+tOflJqaqiFDhig5OVlnn322kpOT9ac//elYz4dO\nFggEVFhYqFtvvVW33norx4sCAACr2nXM6EknnaQFCxboscce0/79+5WZmam4uLhjPRuOkUAgwDGi\nAADAFdoso7t37z7i8j179kT+3Lt3786dCAAAAF1Gm2W0b9++8ng8rV5P1OPxqLGx8ZgMBgAAgBNf\nm8eMDhkyRAMGDNDPf/5z7dy5Uw0NDTp06FDkp76+PlZzAgAA4ATU5p7R9evX67333tPjjz+u888/\nX4MHD9aUKVP0ta99TX6/v90vcuDAARUVFammpkaSNHToUI0YMUKlpaVasmSJDh06pPT0dOXn5ysx\nMfHLvSMAAAAcN456Nv2ZZ56pBx54QDt37tR3v/tdLVmyRDk5OVq3bl37X8Tr1UUXXaRvf/vbuumm\nm7RmzRrt27dPL774oi688ELNnDlTgwYN0ptvvvml3gwAAACOL+26tJMkbdu2TStWrNA///lPnXPO\nOUpPT2/3i6SmpionJ0eSlJiYqMzMTFVWVqqsrCzyrU65ubnasmWLw/EBAABwPGvzY/qysjI99dRT\nWrBggSorK3X99ddr5cqVX+oM+oqKCpWWlqpXr17Kzs7W+++/r4EDB2rTpk06cOBA5HGVlZWqrq6O\nem5KSori49t1NaqYiouLk8/nsz1GlOac3JiXRGZOuTEvicyccnNeEpl1BJk548a8JDJzqrNz8pjW\nTpXX4b2Yubm5mjx5skaMGHH4CR5P1GPGjx/f7herr6/X/PnzNXr0aA0aNEj79+/X3//+d9XW1iov\nL0+rV6+OXP9y+fLlKi4ujnr+mDFjNG7cuHa/HgAAANytzTLafGmntuzYsaNdL9TY2Ki//vWv6t+/\nv0aOHNni/v3796uoqCjy1ZSt7RltbGxUOBxu12vGSmJiouuuLBAfH6+MjAxVVFS4Li+JzJxyY14S\nmTnl5rwkMusIMnPGjXlJZOZUc16dtr627ty5c2envIgxRosXL1ZWVlZUEa2pqVFycrKampq0YsUK\nDRs2LHJfWlqa0tLSWqxr3759amho6JS5Okt8fLzrZmoWDoddORuZOePmvCQyc8qNeUlk1hFk5oyb\n85LIzJaYHByxe/duvfvuu+rRo4ceeeQRSdKECRNUVlamNWvWSJIGDRqkc845JxbjAAAAwCViUkb7\n9Omj2bNnt1g+YMCAyLGoAAAA6HrafWknAAAAoLNRRgEAAGANZRQAAADWUEYBAABgDWUUAAAA1lBG\nAQAAYA1lFAAAANZQRgEAAGANZRQAAADWUEYBAABgDWUUAAAA1sTku+nhbuXl5SooKJAkhUIhBQIB\nyxMBAICugjLaxZWXlys/P18lJSWSpKVLl6qwsJBCCgAAYoKP6bu4goKCSBGVpJKSksheUgAAgGON\nMgoAAABrKKNdXCgUUjAYjNwOBoMKhUIWJwIAAF0Jx4x2cYFAQIWFhZzABAAArKCMQoFAQLNmzbI9\nBgAA6IL4mB4AAADWUEYBAABgDWUUAAAA1lBGAQAAYA1lFAAAANZQRgEAAGANZRQAAADWUEYBAABg\nDWUUAAAA1niMMcb2EO1VV1enuro6uW1kr9erpqYm22NE8Xg8SkhI0KFDh1yXl0RmTrkxL4nMnHJz\nXhKZdQSZOePGvCQyc8rj8Sg9Pb3T1ndcfR1oUlKSqqqq1NDQYHuUKH6/XwcPHrQ9RhSfz6f09HTV\n1NS4Li+JzJxyY14SmTnl5rwkMusIMnPGjXlJZOaUz+fr1PXxMT0AAACsoYwCAADAGsooAAAArDmu\njhlFbJSXl6ugoECSFAqFFAgELE8EAABOVJRRRCkvL1d+fr5KSkokSUuXLlVhYSGFFAAAHBN8TI8o\nBQUFkSIqSSUlJZG9pAAAAJ2NMgoAAABrKKOIEgqFFAwGI7eDwaBCoZDFiQAAwImMY0YRJRAIqLCw\nkBOYAABATFBG0UIgENCsWbNsjwEAALoAPqYHAACANZRRAAAAWEMZBQAAgDWUUQAAAFhDGQUAAIA1\nlFEAAABYQxkFAACANZRRAAAAWEMZBQAAgDV8AxMAAOiyysvLNW/ePHXr1k2TJ09WWlqa7ZG6HMoo\nAADoksrLy5Wfn6+SkhJJ0qJFi1RYWKhAIGB5sq6Fj+kBAECXVFBQECmiklRSUqKCggKLE3VNlFEA\nAABYQxkFAABdUigUUjAYjNwOBoMKhUIWJ+qaOGYUAAB0SYFAQIWFhZzAZBllFAAAdFmBQEB33XWX\nsrKytG/fPjU0NNgeqcuJSRk9cOCAioqKVFNTI0kaOnSoRowYoY8++kgvv/yympqa5PV6ddlll6ln\nz56xGAkAAAAuEJMy6vV6ddFFFyknJ0f19fWaO3euTjvtNL366qsaP368+vfvr23btunVV1/VtGnT\nYjESAAAAXCAmZTQ1NVWpqamSpMTERGVmZqqyslKpqamqq6uTJNXV1UUeAwAAgK4h5seMVlRUqLS0\nVL169VL37t01b948vfLKKzLG6Kabboo8rrKyUtXV1VHPTUlJUXy8+w5zjYuLk8/nsz1GlOacOjuv\nsrIyzZ07V5J08803q3v37h1aT1fKrDO4MS+JzJxyc14SmXUEmTnjxrwkMnOqs3PyGGNMp66xDfX1\n9Zo/f75Gjx6tQYMG6fHHH9fw4cM1aNAgbdq0SWvXrtWUKVMkScuXL1dxcXHU88eMGaNx48bFalx8\nwf79+zVmzBht3rxZkjR48GAVFxcrMzPT8mQAAOB4FbP/BWhsbNSzzz6rs846S4MGDZIk7dmzJ/Ln\nwYMH68UXX4w8fujQocrLy4taR0pKiioqKhQOh2M1drskJiaqvr7e9hhR4uPjlZGR0al5/epXv4oU\nUUnavHmzfvnLX+quu+5yvK6ukllncWNeEpk55ea8JDLrCDJzxo15SWTmVHNenba+TltTG4wxWrx4\nsbKysjRy5MjI8kAgoJ07d6pv377asWNH1Ee+aWlpR7zWlxsvuxAfH++6mZqFw+FOm62xsfGIyzqy\n/q6SWWdxc14SmTnlxrwkMusIMnPGzXlJZGZLTMro7t279e6776pHjx565JFHJEkTJkzQFVdcoZdf\nflnhcFg+n09XXHFFLMZBB4VCIS1dujTyPb58UwUAAPiyYlJG+/Tpo9mzZx/xPsrM8aP5myoKCgok\nHf5vFwgELE8FAACOZ+47bQyuFggENGvWLNtjAACAE4TX9gAAAADouiijAAAAsIYyCgAAAGsoowAA\nALCGMgoAAABrKKMAAACwhjIKAAAAayijAAAAsIYyCgAAAGsoowAAALCGMgoAAABr+G56dKry8nIV\nFBRIkkKhkAKBgOWJAACAm1FG0WnKy8uVn5+vkpISSdLSpUtVWFhIIQUAAK3iY3p0moKCgkgRlaSS\nkpLIXlIAAIAjoYwCAADAGsooOk0oFFIwGIzcDgaDCoVCFicCAABuxzGj6DSBQECFhYWcwAQAANqN\nMopOFQgENGvWLNtjAACA4wQf0wMAAMAayigAAACsoYwCAADAGsooAAAArKGMAgAAwBrKKAAAAKyh\njAIAAMAayigAAACs8RhjjO0h2quurk51dXVy28her1dNTU22x4ji8XiUkJCgQ4cOuS4vicyccmNe\nEpk55ea8JDLrCDJzxo15SWTmlMfjUXp6eqet77j6BqakpCRVVVWpoaHB9ihR/H6/Dh48aHuMKD6f\nT+np6aqpqXFdXhKZOeXGvCQyc8rNeUlk1hFk5owb85LIzCmfz9ep6+NjegAAAFhDGQUAAIA1lFEA\nAABYQxkFAACANZRRAAAAWHNcnU2PE1t5ebkKCgokSaFQSIFAwPJEAADgWKOMwhXKy8uVn5+vkpIS\nSdLSpUtVWFhIIQUA4ATHx/RwhYKCgkgRlaSSkpLIXlIAAHDioowCAADAGsooXCEUCikYDEZuB4NB\nhUIhixMBAIBY4JhRuEIgEFBhYSEnMAEA0MVQRuEagUBAs2bNsj0GAACIIT6mBwAAgDWUUQAAAFhD\nGQUAAIA1lFEAAABYQxkFAACANZRRAAAAWEMZBQAAgDWUUQAAAFhDGQUAAIA1lFEAAABYQxkFAACA\nNZRRAAAAWEMZBQAAgDWUUQAAAFgTH4sXOXDggIqKilRTUyNJGjp0qEaMGKFFixaprKxMklRXV6ek\npCRNnz49FiMBAADABWJSRr1ery666CLl5OSovr5ec+fO1Wmnnaarr7468ph//OMfSkpKisU4AAAA\ncImYfEyfmpqqnJwcSVJiYqIyMzNVVVUVud8Yo02bNunMM8+MxTgAAABwiZjsGf28iooKlZaWqmfP\nnpFlu3btUkpKigKBQGRZZWWlqquro56bkpKi+PiYj3xUcXFx8vl8tseI0pyTG/OSyMwpN+YlkZlT\nbs5LIrOOIDNn3JiXRGZOdXZOHmOM6dQ1tqG+vl7z58/X6NGjNWjQoMjyJUuWqHv37ho5cmRk2fLl\ny1VcXBz1/DFjxmjcuHGxGhcAAADHWMz+F6CxsVHPPvuszjrrrKgi2tjYqC1btuiWW26JevzQoUOV\nl5cXtSwlJUUVFRUKh8Mxmbm9EhMTVV9fb3uMKPHx8crIyHBlXhKZOeXGvCQyc8rNeUlk1hFk5owb\n85LIzKnmvDptfZ22pjYYY7R48WJlZWVF7f2UpH//+9/KyspSWlpa1PK0tLQWyyRp3759amhoOKbz\nOhUfH++6mZqFw2FXzkZmzrg5L4nMnHJjXhKZdQSZOePmvCQysyUmZXT37t1699131aNHDz3yyCOS\npAkTJmjAgAHatGmTzjjjjFiMAQAAAJeJSRnt06ePZs+efcT7rrrqqliMAByXysvLVVBQoPj4eN1w\nww1RJ/nZVl5ernnz5qlbt26aPHnyET/JAADgaNx32hgASYfLXn5+vkpKSiQdPtGvsLDQFYX0i7Mt\nWrTINbMBAI4vfB0o4FIFBQWRsidJJSUlKigosDjRf7h5NgDA8YUyCgAAAGsoo4BLhUIhBYPByO1g\nMKhQKGRxov9w82wAgOMLx4wCLhUIBFRYWOjKE5iaZ+MEJgDAl0UZBVwsEAho1qxZ8vv9OnjwoO1x\nogQCAd11113Kyspy5fV/AQDHBz6mBwAAgDWUUQAAAFhDGQUAAIA1lFEAAABYQxkFAACANZRRAAAA\nWEMZBQAAgDWUUQAAAFhDGQUAAIA1lFEAAABYQxkFAACANZRRAAAAWEMZBQAAgDWUUQAAAFhDGQUA\nAIA1lFEAAABYQxkFAACANZRRAAAAWEMZBQAAgDWUUQAAAFhDGQUAAIA1HmOMsT1Ee9XV1amurk5u\nG9nr9aqpqcn2GFE8Ho8SEhJ06NAh1+UlkZlTbsxLIjOn3JyXRGYdQWbOuDEvicyc8ng8Sk9P77T1\nxXfammIgKSlJVVVVamhosD1KFL/fr4MHD9oeI4rP51N6erpqampcl5dEZk65MS+JzJxyc14SmXUE\nmTnjxrwkMnPK5/N16vr4mB4AAADWUEYBAABgDWUUAAAA1lBGAQAAYA1lFAAAANZQRgEAAGANZRQA\nAADWUEYBAABgDWUUAAAA1lBGAQAAYA1lFAAAANZQRgEAAGANZRQAAADWUEYBAABgDWUUAAAA1lBG\nAQAAYA1lFAAAANZQRgEAAGANZRQAAADWUEYBAABgDWUUAAAA1lBGAQAAYA1lFAAAANZQRgEAAGAN\nZRQAAADWUEYBAABgTXwsXuTAgQMqKipSTU2NJGno0KEaMWKEJGn16tVas2aNPB6PgsGgLrzwwliM\nBAAAABeISRn1er266KKLlJOTo/r6es2dO1ennXaaqqurtXXrVs2YMUNxcXGRsgoAAICuISZlNDU1\nVampqZKkxMREZWZmqrKyUuvWrdMFF1yguLg4SVJycnIsxgEAAIBLxKSMfl5FRYVKS0vVq1cvvfrq\nq9q1a5def/11xcfHa9KkSerZs6ckqbKyUtXV1VHPTUlJUXx8zEc+qri4OPl8PttjRGnOyY15SWTm\nlBvzksjMKTfnJZFZR5CZM27MSyIzpzo7p5imXl9fr2effVYXX3yxEhMT1dTUpLq6OoVCIe3Zs0eL\nFi3S7bffLklau3atiouLo57fp08f5efnKyMjI5ZjH5cqKyu1fPlyDR06lLzaicycIzNnyMs5MnOO\nzJwjM2c+n1daWtqXXl/MzqZvbGzUs88+q7POOkuDBg2SJKWlpUX+3LNnT3k8HtXW1ko6fJLTzTff\nHPn56le/ql27drXYW4ojq66uVnFxMXk5QGbOkZkz5OUcmTlHZs6RmTOdnVdM9owaY7R48WJlZWVp\n5MiRkeUDBw7Ujh071LdvX+3fv1+NjY3q1q2bpMNFtTPaNgAAANwrJmV09+7devfdd9WjRw898sgj\nkqQJEybonHPO0eLFi/Xwww8rLi5OX/3qV2MxDgAAAFwiJmW0T58+mj179hHv+9rXvhaLEQAAAOBC\ncbNba4kuY4xRQkKC+vbtq8TERNvjuB55OUdmzpGZM+TlHJk5R2bOkZkznZ2XxxhjOmEuAAAAwDH3\nXVBL0vLly7Vu3brIRfAnTJigAQMGSJJWrlyp9evXy+Px6JJLLlH//v0lSXv37tULL7ygcDisAQMG\n6JJLLrE2vxts27ZNS5culTFG5557ri644ALbI7nCH/7wByUmJsrr9crr9ermm29WbW2tnnvuOX32\n2WdKT0/X1VdfLb/fL6n17e1E9sILL2jbtm1KTk7WzJkzJalDGXWl38kjZcbfY61r7Sui2c5a11pm\nbGeta2ho0Pz58xUOh9XY2KiBAwdq4sSJbGetaC2vmGxjxoWWL19u3nzzzRbLP/nkE/Pwww+bcDhs\nysvLzYMPPmiampqMMcbMmTPHfPjhh8YYYxYuXGhKSkpiOrObNDY2mgcffNCUl5ebcDhsHn74YfPp\np5/aHssV/vCHP5iampqoZf/4xz/MypUrjTHGrFy50rzyyivGmCNvb42NjTGfOdZ27txp9u7da/78\n5z9HljnJqCv+Th4pM/4ea11lZaXZu3evMcaYuro688c//tF8+umnbGdtaC0ztrO21dfXG2OMCYfD\nZu7cuWbnzp1sZ204Ul6x2MZidp3RzrB161adeeaZiouLU0ZGhgKBgD766CNVVVXp0KFD6tWrlyRp\nyJAhev/99y1Pa8+ePXsUCASUkZGhuLg4nXHGGV06j6PZunWrzj77bEnR286Rtrc9e/bYHDUm+vTp\no6SkpKhlTjLqir+TR8qsNWR2+Cuic3JyJEV/RTTbWetay6w1ZHZYQkKCpMPXOjfGyO/3s5214Uh5\ntaYz83Llx/SStHr1am3YsEGnnHKKJk2aJL/fr6qqqsibkw5fi7SqqkpxcXFR1yRtXt5VVVZW6qST\nTorcTktL6xIlqr0WLFggj8ejYcOGaejQoaqpqVFKSoqkw1852/wxWGvbW1fkNCN+Jw/j77Gj+/xX\nRLOdtc/nM/vwww/ZztrQ1NSkOXPmqKKiQsOGDVN2djbbWRuOlNfmzZuP+TZmrYwuWLDgiFfuHz9+\nvIYNG6YxY8ZIkpYtW6ZXXnlFV155ZaxHPG55PB7bI7jWjTfeqNTUVNXU1GjBggXKzMyMup/sjo6M\n2oe/x47ui18R/XlsZ0f2xczYztrm9Xo1Y8YM1dXVaeHChdqxY0fU/Wxn0Y6UVyy2MWtldMqUKe16\n3LnnnqunnnpK0uGPKQ4cOBC5r7KyUmlpaUpNTY36uKKyslKpqamdO/BxpLWcoMh2kZycrEGDBmnP\nnj1KTk5WVVWVUlNTVVVVFTlImxz/w2lG/E4qsudF4u+xIznSV0SznbXtSJmxnbVPUlKSgsGg9u7d\ny3bWDp/Pq1+/fpHlx2obc+Uxo5/fnfv+++8rOztbkpSXl6eNGzcqHA6roqJC5eXl6tmzp1JTU5WY\nmKiPPvpIxhht2LBBAwcOtDW+daeccorKy8tVUVGhcDisjRs3Ki8vz/ZY1h06dEj19fWRP2/fvl3Z\n2dnKy8vThg0bJEnvvPNOZNtpbXvripxmxO8kf4+1xbTyFdFsZ61rLTO2s9bV1NTo4MGDkg6fKb59\n+3bl5OSwnbWitbxisY258jqjzz//vEpLS+XxeJSenq4rrrgi8n9/K1as0Pr16+X1eo94GYGGhgYN\nGDBAl156qc23YF3zpZ2ampp07rnnatSoUbZHsq6iokJPP/20pMPHxZx11lkaNWqUamtrtWjRIh04\ncKDFZT5a295OZM8995x27typ2tpapaSkaNy4ccrLy3OcUVf6nfxiZmPHjtXOnTv5e6wVu3bt0mOP\nPaYePXpEPiadMGGCevbsyXbWitYye++999jOWvHJJ5+oqKhIxhgZYzRkyBCdf/75Hfo7vytk1lpe\nsehkriyjAAAA6Bpc+TE9AAAAugbKKAAAAKyhjAIAAMAayigAAACsoYwCAPD/27v72KaqNw7g37uN\nl61ru7vCXru2GJi6aBxhMQzINjAgIRiRiBu42mqAsChhCfGNMVtkgC+bkBgcxkwzhInhr+EoRmUU\nx8QNlCABxTjbvfCiwma37q2lfX5/LNy0W7tNhnQ/93ySJrv33HvOc885IQ/n9vYyxkKGk1HGGGOM\nMRYynIwyxu4Js9kMvV5/x+cXFBSgpKTkLkY0YNmyZfj000/ver3szhmNRhQXF9/1Yxlj41PIXgfK\nGAsNnU6HP//8E+Hh4ZDJZFi8eDH27t37r7/qdKzvgC4vLx9zDGazGU1NTX7Jp8ViGXO9/zU6nQ4f\nf/wxFi1aFJL2BUEY9Xz5J8cyxsYnXhllbIIRBAE1NTXo6urC+fPnceHChX9lxXGwsbxfw+v13sVI\n/v94PJ572p4gCHc8Xrff3jJW/D4WxiYOTkYZm8Di4+OxZMkSXLx4Udr3/fffY968eRBFEenp6Th5\n8qRUZrPZkJWVBYVCgcWLF+PFF1+Ubr1brVakpKT41a/T6VBbWxuw7VWrViExMRExMTHIzs7GpUuX\npDKj0YiCggIsW7YM0dHROHHihN/t2CeeeAJyuVz6hIeHY//+/QCATZs2QaPRQKlUIiMjA6dOnQIA\nfPnll9i1axc+//xzyOVyzJ49GwCQk5ODiooKAAMJUElJCXQ6HeLj42EwGNDZ2QkAsNvtCAsLw/79\n++NqX6wAAAj7SURBVKHVajF9+nTs3LkzaN8ajUZs2LABS5YsgUKhQE5ODlpaWqTyYHECAyu4Tz/9\nNPR6PZRKJSorK3HmzBlkZmZCFEUkJSVh48aNcLvd0jlhYWEoLy/HrFmzoFAo8MYbb6CpqQmZmZmI\niYlBXl6e3/E1NTVIT0+HKIqYP38+Lly4AADQ6/VoaWmR+ri0tHTEeZGTk4OtW7di/vz5kMlksNls\nQftlNOPvy2q1Qq1WY9euXZg+fTpmzJiBqqoqv2Pa29uxfPlyKBQKzJ07F7///vuo+pkxNk4QY2xC\n0el09M033xARUWtrKz388MO0bds2IiJqa2sjlUpFx44dIyKir7/+mlQqFd24cYOIiObOnUsvv/wy\nud1uOnXqFCkUCtLr9UREdOLECVKr1UPaOn78OBERmUwmys/Pl8o++eQTcjqd5HK5qLCwkNLT06Uy\ng8FASqWSvvvuOyIi6uvrI6PRSMXFxUOux2KxUHJyMrW1tRER0YEDB6i9vZ08Hg+VlZVRQkIC9ff3\nExGR2WyW4r0tJyeHKioqiIiooqKCZs6cSTabjZxOJ61cuVI63mazkSAItH79eurr66Pz58/TlClT\n6Oeffw7YzwaDgeRyOdXV1VF/fz9t2rSJFixYIJUPF6fJZKJJkyZRdXU1ERH19vbSDz/8QA0NDeTx\neMhut9ODDz5Ie/bskeoTBIFWrFhBXV1ddPHiRZo8eTItXLiQbDYbORwOSktLo8rKSiIi+vHHHyku\nLo4aGxvJ6/VSZWUl6XQ6crlcQ8aNaOR5kZ2dTVqtli5dukQej4fcbnfAPvE13PgbjUbaunUrEQ3M\nq4iICNq8eTO5XC46efIkyWQyunz5stTPKpWKzpw5Q7du3aJnn32W8vLyRtXPjLHxgZNRxiYYrVZL\n0dHRJJfLpQTG4/EQEdFbb701JFl7/PHHqbKykpqbmykiIoJ6e3ulsvz8/DtORn11dHSQIAjU2dlJ\nRAMJhsFg8DvGN0G57fLlyxQXF0f19fVBr1cURfrpp5+CxuCbjC5atIjKy8v96p80aRJ5PB4pGb1y\n5YpU/uijj9KhQ4cCtmswGGj16tXSttPppPDwcClpHinO7OzsoNdERLR792566qmnpG1BEKTknYho\nzpw59M4770jbmzdvpsLCQiIi2rBhw5DE/v7776dvv/2WiIYmo8PNC6KBPjSZTMPGO5zB4x8oGe3p\n6ZGOf+aZZ2j79u1ENNDP69atk8osFgs98MADQdvy7WfG2PjAt+kZm2AEQUB1dTU6OzthtVpRW1uL\ns2fPAgCam5tx+PBhiKIoferr63H9+nVcvXoVsbGxmDp1qlRXSkrKHX23z+Px4LXXXsPMmTOhVCox\nY8YMAMCNGzekGAff8h/M4XDgySefxI4dOzBv3jxpf2lpKdLS0hATEwNRFOFwOKR6R3Lt2jVotVpp\nW6PR4NatW/jjjz+kfQkJCdLfUVFR6O7uDliXIAhQq9XStkwmQ2xsLK5evTqqOH3PBYBff/0Vy5cv\nR2JiIpRKJYqKinDz5k2/Y+Lj46W/IyMj/banTp0qxdrc3IyysjK/cW5ra5NiG2y4eXHbSOPly+v1\nDjv+g4miiMjISGlbq9Xi2rVrAAb6efB1O51OaXss84Exdm9wMsrYBJaVlYWNGzfi1VdfBTCQfOn1\nenR0dEifrq4uvPLKK0hMTER7ezt6e3ul81taWqQnmWUyGXp6eqQyj8eDv/76K2C7VVVVOHLkCI4f\nPw6HwyF9x3C0ia3X68WaNWvw2GOPYe3atdL+uro6vPvuuzh8+DD+/vtvdHR0QKlUSvWO9NR1UlIS\n7Ha73/VFRET4JTujRURobW2Vtp1OJ9rb25GUlDRinIFiLSgoQFpaGn777Tc4HA7s2LHjHz3Y5Vuf\nRqNBUVGR3zg7nU7k5uYGbHu4eREs3uEcPHhwxPH3ra+jo8NvbjU3NyMpKWnEdkbTz4yx0ONklLEJ\nrrCwEI2NjWhoaEB+fj6++OILfPXVV/B4POjr64PVasWVK1eg1WqRkZEBs9kMt9uN06dPo6amRqon\nNTUVfX19sFgscLvdKCkpQX9/f8A2nU4npkyZgtjYWHR3d2PLli1+5YGSBd99RUVF6OnpwZ49e/yO\n6erqQkREBKZNmwaXy4U333xTegAJGFjVtNvtQZOR1atXY/fu3bDb7XA6ndiyZQvy8vIQFhb8n8rh\nEhuLxYL6+nq4XC4UFxcjMzMTycnJI8YZiNPphFwuR1RUFH755ZdR/dSVb2zk85T7unXrsG/fPjQ2\nNoKI0N3djaNHj0orivHx8WhqapLOHW5eBOsHs9mMhQsXBr2WkcZ/cH0mkwlutxt1dXU4evQoVq1a\nFbBdX3fSz4yxe4+TUcYmuGnTpsFgMODtt9+GWq1GdXU1du7cibi4OGg0GpSVlUkrcAcPHsTp06eh\nUqlQXFyM3NxcTJ48GQCgVCrxwQcfYO3atVCr1YiOjva7dev7e5DPPfcctFotkpOT8dBDDyEzM9Nv\nJSzQb0f67jt06BAaGhogiqL0RP1nn32GpUuXYunSpUhNTYVOp0NkZCQ0Go1Ux+0ERqVSISMjY0hf\nvPDCC9Dr9cjKysJ9992HqKgovP/++34xDBZsRVAQBKxZswbbtm2DSqXCuXPncODAAQAYMc5A119a\nWoqqqiooFAqsX78eeXl5Q/psuNh865wzZw4++ugjvPTSS4iNjcWsWbOkXyMAgNdffx0lJSUQRRHv\nvfde0Hkx3Epua2srFixYELBv/un4JyQkSL8ioNfr8eGHHyI1NTVoX93eHqmfGWPjg0B8v4Ixdody\nc3ORlpYGk8kU6lDGneeffx5qtRrbt28PdSghMXv2bNTW1kIUxTHVY7Vaodfr/b7ywBj7b+GVUcbY\nqJ09exZNTU3wer04duwYjhw5ghUrVoQ6rHFpov8//9y5c2NORBljEwO/DpQxNmrXr1/HypUrcfPm\nTaSkpGDfvn145JFHQh3WuMSvqbx7uB8Z+2/j2/SMMcYYYyxk+DY9Y4wxxhgLGU5GGWOMMcZYyHAy\nyhhjjDHGQoaTUcYYY4wxFjKcjDLGGGOMsZD5Hxy3gh+4b1adAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1125523d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (288112461)>"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ggplot(scores_df, aes(x='alphas', y='values')) + geom_point() +\\\n",
    "        labs('Regularization parameter, alpha', 'Model MSE', 'Tests of various alphas wrt MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.1823079104\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (77,) and (16,900) not aligned: 77 (dim 0) != 16 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-437-80ea145343ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (77,) and (16,900) not aligned: 77 (dim 0) != 16 (dim 0)"
     ]
    }
   ],
   "source": [
    "def train_error(X, Y, alpha):\n",
    "    lr_test = Ridge(alpha=alpha)\n",
    "    lr_test.fit(X, Y)\n",
    "    pred = lr_test.predict(X)\n",
    "    submission = lr_test.predict(test)\n",
    "    return score(Y, pred)\n",
    "print(train_error(X, Y, 50))\n",
    "\n",
    "\n",
    "score(Y, beta.dot(X.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = skcv.cross_val_score(Ridge(alpha=30), X, Y, scoring=scorefun, cv=5)\n",
    "fn_score = np.mean(scores)\n",
    "print(fn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.100008530948\n",
      "33.0484876797\n",
      "27.2561361627\n"
     ]
    }
   ],
   "source": [
    "# Fit regression model\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_lin = SVR(kernel='linear', C=1e3)\n",
    "svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "y_rbf = svr_rbf.fit(X, Y).predict(X)\n",
    "y_lin = svr_lin.fit(X, Y).predict(X)\n",
    "y_poly = svr_poly.fit(X, Y).predict(X)\n",
    "\n",
    "# Training error\n",
    "print(score(Y, y_rbf))\n",
    "print(score(Y, y_lin))\n",
    "print(score(Y, y_poly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.6313552457\n",
      "33.8621522178\n",
      "58.5796997601\n"
     ]
    }
   ],
   "source": [
    "# CV error\n",
    "scores = skcv.cross_val_score(svr_rbf, X, Y, scoring=scorefun, cv=20)\n",
    "print(np.mean(scores))\n",
    "scores = skcv.cross_val_score(svr_lin, X, Y, scoring=scorefun, cv=20)\n",
    "print(np.mean(scores))\n",
    "scores = skcv.cross_val_score(svr_poly, X, Y, scoring=scorefun, cv=20)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.11485941952e+12\n",
      "5.8289734934e+12\n",
      "6.09019670652e+12\n",
      "6.04276884143e+12\n",
      "4.89985129425e+12\n",
      "5.43352212857e+12\n",
      "4.86155528698e+12\n",
      "4.13082039684e+12\n",
      "3.73465244318e+12\n",
      "3.36498592909e+12\n",
      "3.2363210805e+12\n",
      "3.10785588741e+12\n",
      "2.56670016102e+12\n",
      "1.97020352099e+12\n",
      "52.0622731684\n",
      "52.0713955546\n",
      "52.0701111235\n"
     ]
    }
   ],
   "source": [
    "# Iteration through the list of alphas and generation of accuracy from the testing set\n",
    "alpha_list = [ 0.01, 0.1, 0.5, 1, 5, 10, 30, 50, 75, 100, 135, 150, 200, 300, 100000, 1000000, 10000000]\n",
    "scores_df = pd.DataFrame(alpha_list, columns=['alphas'])\n",
    "scores_df['values'] = 1\n",
    "for i, alpha_num in enumerate(alpha_list):\n",
    "    sgd = SGDRegressor(alpha=alpha_num, average=False, epsilon=0.1, eta0=0.01,\n",
    "       fit_intercept=True, l1_ratio=0.25, learning_rate='invscaling',\n",
    "       loss='squared_loss', n_iter=50, penalty='elasticnet', power_t=0.25,\n",
    "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
    "\n",
    "    #lr.fit(X, Y)\n",
    "    #Xtrain, Xtest, Ytrain, Ytest = skcv.train_test_split(X, Y, train_size=0.70)\n",
    "    scores = skcv.cross_val_score(sgd, X, Y, scoring=scorefun, cv=50)\n",
    "    fn_score = np.mean(scores)\n",
    "    print(fn_score)\n",
    "    scores_df.iloc[i, 1] = fn_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAH+CAYAAAC7sEcoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e24c850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (281240737)>"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ggplot(scores_df, aes(x='alphas', y='values')) + geom_point() +\\\n",
    "        labs('Regularization parameter, alpha', 'Model MSE', 'Tests of various alphas wrt MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_test = Ridge(alpha=40)\n",
    "lr_test.fit(X, Y)\n",
    "submission = lr_test.predict(test)\n",
    "np.savetxt('first.csv', submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best = grid_search.best_estimator_\n",
    "best.fit(X, Y)\n",
    "submission = test.dot(beta)\n",
    "np.savetxt('last.csv', submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = KNeighborsRegressor()\n",
    "param_grid = {'n_neighbors': [1, 2, 3, 4, 5, 6, 8],\n",
    "             'leaf_size': [2, 5, 10, 20, 30, 50, 70],\n",
    "             'algorithm': ['ball_tree', 'brute', 'kd_tree'],\n",
    "             'weights': ['uniform', 'distance']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_neighbors=5, p=2, weights='uniform'),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 8], 'weights': ['uniform', 'distance'], 'leaf_size': [2, 5, 10, 20, 30, 50, 70], 'algorithm': ['ball_tree', 'brute', 'kd_tree']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
       "       scoring=make_scorer(<lambda>), verbose=0)"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = skgs.GridSearchCV(neigh, param_grid, scoring=neg_scorefun, cv=10)\n",
    "grid_search.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='ball_tree', leaf_size=2, metric='minkowski',\n",
      "          metric_params=None, n_neighbors=5, p=2, weights='distance')\n",
      "-37.2063333875\n",
      "[mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'ball_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'brute'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 2, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 5, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 10, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 20, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 30, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 50, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -45.64318, std: 4.07433, params: {'n_neighbors': 1, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -40.76628, std: 3.05077, params: {'n_neighbors': 2, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -40.71449, std: 3.02879, params: {'n_neighbors': 2, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -38.57584, std: 3.00176, params: {'n_neighbors': 3, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -38.53312, std: 2.97552, params: {'n_neighbors': 3, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -37.72660, std: 2.71875, params: {'n_neighbors': 4, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -37.66336, std: 2.72426, params: {'n_neighbors': 4, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -37.29939, std: 3.00150, params: {'n_neighbors': 5, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -37.20633, std: 2.96977, params: {'n_neighbors': 5, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -37.38508, std: 3.50128, params: {'n_neighbors': 6, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -37.25814, std: 3.45127, params: {'n_neighbors': 6, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -37.68721, std: 3.64749, params: {'n_neighbors': 8, 'weights': 'uniform', 'leaf_size': 70, 'algorithm': 'kd_tree'}, mean: -37.52582, std: 3.61009, params: {'n_neighbors': 8, 'weights': 'distance', 'leaf_size': 70, 'algorithm': 'kd_tree'}]\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name MLPRegressor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-680-751e3a9b7d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m param_grid = {'hidden_layer_sizes': [(100,), (50, 2)],\n\u001b[1;32m      4\u001b[0m              'alpha': [0.1, 1]}\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name MLPRegressor"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = skgs.GridSearchCV(mlp, param_grid, scoring=neg_scorefun, cv=10)\n",
    "grid_search.fit(X, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
